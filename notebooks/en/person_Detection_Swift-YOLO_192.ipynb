{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlindmark/GrooveAIVision/blob/master/notebooks/en/person_Detection_Swift-YOLO_192.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY1CB5yiMhT5"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <h1>Welcom to SSCMA for Google Colab Training Example 🔥 </h1>\n",
        "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://files.seeedstudio.com/sscma/docs/images/SSCMA-Hero.png\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQbLeajMMhT6"
      },
      "source": [
        "# person Detection - Swift-YOLO\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/person_Detection_Swift-YOLO_192.ipynb)\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** [Person](https://universe.roboflow.com/hanzhou-7mktt/ssperson/dataset/7#)\n",
        "\n",
        "**Class:** `person`\n",
        "\n",
        "![person Detection](https://files.seeedstudio.com/sscma/static/detection_person.png)\n",
        "\n",
        "The model is a Swift-YOLO model trained on the person detection dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOtQQHvoMhT7"
      },
      "source": [
        "## ⚙️Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nCjcrI-DMhT7",
        "outputId": "14e25dbe-3b96-4821-de95-f1eac6cac306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ethos-u-vela'...\n",
            "remote: Counting objects: 79, done\u001b[K\n",
            "remote: Finding sources: 100% (10691/10691)\u001b[K\n",
            "remote: Total 10691 (delta 6890), reused 9312 (delta 6890)\u001b[K\n",
            "Receiving objects: 100% (10691/10691), 5.66 MiB | 5.58 MiB/s, done.\n",
            "Resolving deltas: 100% (6890/6890), done.\n",
            "/content/ethos-u-vela\n",
            "Processing /content/ethos-u-vela\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flatbuffers==24.3.25 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela==4.1.0rc2) (24.3.25)\n",
            "Requirement already satisfied: numpy>1.10.0 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela==4.1.0rc2) (1.26.4)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela==4.1.0rc2) (5.3.0)\n",
            "Building wheels for collected packages: ethos-u-vela\n",
            "  Building wheel for ethos-u-vela (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ethos-u-vela: filename=ethos_u_vela-4.1.0rc2-cp310-cp310-linux_x86_64.whl size=1665887 sha256=63cd7f1cd05cb2331ce45217390383ff1689e03ef77bb264aade08aec4b898a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/bb/a4/8cbf7845835c564e303787c5b86a3233501a9126e0070abb2d\n",
            "Successfully built ethos-u-vela\n",
            "Installing collected packages: ethos-u-vela\n",
            "Successfully installed ethos-u-vela-4.1.0rc2\n",
            "/content\n",
            "Cloning into 'ModelAssistant'...\n",
            "remote: Enumerating objects: 15259, done.\u001b[K\n",
            "remote: Counting objects: 100% (3219/3219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1152/1152), done.\u001b[K\n",
            "remote: Total 15259 (delta 2215), reused 2604 (delta 2037), pack-reused 12040 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15259/15259), 25.30 MiB | 24.16 MiB/s, done.\n",
            "Resolving deltas: 100% (8979/8979), done.\n",
            "/content/ModelAssistant\n",
            "Checking if CUDA available... \u001b[032mOK\u001b[m\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
            "Installing base deps... Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from -r requirements/export.txt (line 2))\n",
            "  Downloading https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations<=1.3.1 (from -r requirements/base.txt (line 2))\n",
            "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting libusb1 (from -r requirements/base.txt (line 3))\n",
            "  Downloading libusb1-3.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cbor (from -r requirements/base.txt (line 7))\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 8)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 12)) (4.10.0.84)\n",
            "Collecting openmim>=0.3.7 (from -r requirements/base.txt (line 16))\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 17)) (24.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 18)) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 19)) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 21)) (0.24.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 22)) (1.5.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 26)) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 30)) (2.17.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 31)) (4.66.6)\n",
            "Collecting pyvww (from -r requirements/base.txt (line 35))\n",
            "  Downloading pyvww-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pnnx==0.0.4 (from -r requirements/inference.txt (line 2))\n",
            "  Downloading pnnx-0.0.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting ncnn>=1.0.20230517 (from -r requirements/inference.txt (line 3))\n",
            "  Downloading ncnn-1.0.20240820-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (26 kB)\n",
            "Collecting onnx>=1.14.0 (from -r requirements/inference.txt (line 4))\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxmltools>=1.11.2 (from -r requirements/inference.txt (line 5))\n",
            "  Downloading onnxmltools-1.12.0-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting onnxruntime>=1.15.1 (from -r requirements/inference.txt (line 6))\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnxsim>=0.4.33 (from -r requirements/inference.txt (line 7))\n",
            "  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements/inference.txt (line 8)) (4.25.5)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/inference.txt (line 9)) (2.17.1)\n",
            "Requirement already satisfied: ethos-u-vela in /usr/local/lib/python3.10/dist-packages (from -r requirements/export.txt (line 8)) (4.1.0rc2)\n",
            "Collecting black>=23.3.0 (from -r requirements/tests.txt (line 1))\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.12.0 (from -r requirements/tests.txt (line 2))\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pre-commit>=3.3.3 (from -r requirements/tests.txt (line 3))\n",
            "  Downloading pre_commit-4.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting ruff>=0.0.275 (from -r requirements/tests.txt (line 4))\n",
            "  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (1.13.1)\n",
            "Collecting qudida>=0.0.4 (from albumentations<=1.3.1->-r requirements/base.txt (line 2))\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (4.10.0.84)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (8.1.7)\n",
            "Collecting colorama (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2024.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 22)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->-r requirements/base.txt (line 26)) (1.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.1.3)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 35)) (2.0.8)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 35)) (0.15.1)\n",
            "Collecting portalocker (from ncnn>=1.0.20230517->-r requirements/inference.txt (line 3))\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.37.1)\n",
            "Collecting ruamel.yaml>=0.16.12 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting igraph>=0.9 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela->-r requirements/export.txt (line 8)) (5.3.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (2.1.0)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading identify-2.6.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading virtualenv-20.27.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.45.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements/base.txt (line 26)) (2.22)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2024.8.30)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.0.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting ordered-set (from model-index->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->pyvww->-r requirements/base.txt (line 35)) (3.8.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyvww->-r requirements/base.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (18.1.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (3.2.0)\n",
            "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas>=2.0.0->-r requirements/base.txt (line 18))\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting requests (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting rich (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard>=2.12.3->-r requirements/base.txt (line 30))\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tqdm>=4.65.0 (from -r requirements/base.txt (line 31))\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16)) (43.0.3)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'pnnx' candidate (version 0.0.4 at https://files.pythonhosted.org/packages/2a/61/e70626f1e94026da417e6ecd5ad303d0ef3fe7a32fb3fff821bb07f1f4e2/pnnx-0.0.4-py3-none-any.whl (from https://pypi.org/simple/pnnx/))\n",
            "Reason for being yanked: <none given>\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading pnnx-0.0.4-py3-none-any.whl (49.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libusb1-3.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvww-0.1.1-py3-none-any.whl (8.9 kB)\n",
            "Downloading ncnn-1.0.20240820-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxmltools-1.12.0-py2.py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.0.1-py2.py3-none-any.whl (218 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.2-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.27.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading openxlab-0.1.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: cbor, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53429 sha256=87aac6e7b6d11d4e6975284bd3cad9cdb08b9bf2250d22df9f8f3d05658757b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112372 sha256=d68f5a23be8b868adfee01fe309545ca4d3c41aaae301cb3cf4e369158342d91\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535316 sha256=8579de23b98ae6a881e5143d9f2d5e52f28cd3cc2f730bde43bcb53f6bd26256\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/11/5e/08e7cb4e03a3e83b4862edd12d1143c8d3936a3dd57a3ee46d\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=b9a555fdeb263daebe0079b3f44382a30f1ba6f14a5dd6850d510ce74ce872b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built cbor oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: texttable, pytz, pnnx, libusb1, distlib, crcmod, cbor, urllib3, tqdm, setuptools, ruff, ruamel.yaml.clib, pycryptodome, portalocker, pathspec, ordered-set, onnx, nodeenv, mypy-extensions, jmespath, isort, igraph, identify, humanfriendly, filelock, colorama, cfgv, virtualenv, ruamel.yaml, rich, requests, onnxmltools, model-index, coloredlogs, black, TinyNeuralNetwork, qudida, pre-commit, onnxsim, onnxruntime, ncnn, aliyun-python-sdk-core, aliyun-python-sdk-kms, albumentations, oss2, openxlab, opendatalab, openmim, pyvww\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.2\n",
            "    Uninstalling pytz-2024.2:\n",
            "      Successfully uninstalled pytz-2024.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.6\n",
            "    Uninstalling tqdm-4.66.6:\n",
            "      Successfully uninstalled tqdm-4.66.6\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\n",
            "pymc 5.18.2 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\n",
            "pytensor 2.26.3 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.49 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TinyNeuralNetwork-0.1.1 albumentations-1.3.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 black-24.10.0 cbor-1.0.0 cfgv-3.4.0 colorama-0.4.6 coloredlogs-15.0.1 crcmod-1.7 distlib-0.3.9 filelock-3.14.0 humanfriendly-10.0 identify-2.6.2 igraph-0.11.8 isort-5.13.2 jmespath-0.10.0 libusb1-3.1.0 model-index-0.1.11 mypy-extensions-1.0.0 ncnn-1.0.20240820 nodeenv-1.9.1 onnx-1.17.0 onnxmltools-1.12.0 onnxruntime-1.20.1 onnxsim-0.4.36 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.2 ordered-set-4.1.0 oss2-2.17.0 pathspec-0.12.1 pnnx-0.0.4 portalocker-3.0.0 pre-commit-4.0.1 pycryptodome-3.21.0 pytz-2023.4 pyvww-0.1.1 qudida-0.0.4 requests-2.28.2 rich-13.4.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.12 ruff-0.8.0 setuptools-60.2.0 texttable-1.7.0 tqdm-4.65.2 urllib3-1.26.20 virtualenv-20.27.1\n",
            "Installing OpenMIM deps... \n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcls>=1.0.0.rc6 (from -r requirements/mmlab.txt (line 2))\n",
            "  Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting mmcv-full<=2.1.0 (from -r requirements/mmlab.txt (line 3))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv_full-1.7.2-cp310-cp310-manylinux1_x86_64.whl (70.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmdet<3.1.0,>=3.0.0 (from -r requirements/mmlab.txt (line 4))\n",
            "  Downloading mmdet-3.0.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting mmengine>=0.8.2 (from -r requirements/mmlab.txt (line 5))\n",
            "  Downloading mmengine-0.10.5-py3-none-any.whl.metadata (20 kB)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.8.0)\n",
            "Collecting modelindex (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading modelindex-0.0.2-py3-none-any.whl.metadata (756 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (13.4.2)\n",
            "Collecting addict (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (6.0.2)\n",
            "Collecting yapf (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.10.0.84)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.16.0)\n",
            "Collecting terminaltables (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4))\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->-r requirements/mmlab.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.11)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (8.1.7)\n",
            "Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl (906 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.1/906.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmengine-0.10.5-py3-none-any.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.3/452.3 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, yapf, terminaltables, modelindex, mmcv-full, mmengine, mmcls, mmdet\n",
            "Successfully installed addict-2.4.0 mmcls-1.0.0rc6 mmcv-full-1.7.2 mmdet-3.0.0 mmengine-0.10.5 modelindex-0.0.2 terminaltables-3.1.10 yapf-0.43.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcv==2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.0.0-cp310-cp310-manylinux1_x86_64.whl (74.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (0.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (3.8.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (2.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.0.0) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.0.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.2.0->mmcv==2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Obtaining file:///content/ModelAssistant\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from sscma==2.0.0rc3)\n",
            "  Using cached https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "Requirement already satisfied: torch<=2.0.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: torchaudio<=2.0.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: torchvision<=0.15.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.15.1)\n",
            "Requirement already satisfied: albumentations<=1.3.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: libusb1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.1.0)\n",
            "Requirement already satisfied: cbor in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.10.0.84)\n",
            "Requirement already satisfied: openmim>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.3.9)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (24.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (6.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.24.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.5.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.17.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.65.2)\n",
            "Requirement already satisfied: pyvww in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.1.1)\n",
            "Requirement already satisfied: pnnx==0.0.4 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: ncnn>=1.0.20230517 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.20240820)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.17.0)\n",
            "Requirement already satisfied: onnxmltools>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.12.0)\n",
            "Requirement already satisfied: onnxruntime>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.20.1)\n",
            "Requirement already satisfied: onnxsim>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.4.36)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.25.5)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.17.1)\n",
            "Requirement already satisfied: ethos-u-vela in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.1.0rc2)\n",
            "Requirement already satisfied: black>=23.3.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (24.10.0)\n",
            "Requirement already satisfied: isort>=5.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (5.13.2)\n",
            "Requirement already satisfied: pre-commit>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.0.1)\n",
            "Requirement already satisfied: ruff>=0.0.275 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.8.0)\n",
            "Requirement already satisfied: mmcls>=1.0.0.rc6 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0rc6)\n",
            "Requirement already satisfied: mmcv-full<=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.7.2)\n",
            "Requirement already satisfied: mmdet<3.1.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: mmengine>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.10.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (1.13.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (4.10.0.84)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.12.2)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.8.0)\n",
            "Requirement already satisfied: modelindex in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (13.4.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (0.43.0)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.8)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (3.1.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->sscma==2.0.0rc3) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.28.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.13.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.0.10)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (24.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2024.2)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (2.6.2)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (20.27.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->sscma==2.0.0rc3) (1.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (60.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.1.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.1->sscma==2.0.0rc3) (0.45.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (18.1.8)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela->sscma==2.0.0rc3) (5.3.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.12 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.18.6)\n",
            "Requirement already satisfied: igraph>=0.9 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.11.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->sscma==2.0.0rc3) (2.22)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (1.7.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.12.0->sscma==2.0.0rc3) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.12.0->sscma==2.0.0rc3) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (2024.8.30)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.2.12)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->sscma==2.0.0rc3) (0.3.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->sscma==2.0.0rc3) (3.0.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.15.1->sscma==2.0.0rc3) (10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.2.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim>=0.3.7->sscma==2.0.0rc3) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (3.21.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.17.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (43.0.3)\n",
            "Building wheels for collected packages: sscma\n",
            "  Building editable for sscma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sscma: filename=sscma-2.0.0rc3-0.editable-py3-none-any.whl size=11225 sha256=0e2c44c77e0a2705fb54f464e54e3c0d319a315265beaa49ea0bb5ee6f0fc423\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qlgn2oez/wheels/90/1c/ba/0dcfb496beef1b933cf590042cc252e1a365a514ee48989a82\n",
            "Successfully built sscma\n",
            "Installing collected packages: sscma\n",
            "Successfully installed sscma-2.0.0rc3\n",
            "Finished setup... \u001b[032mOK\u001b[m\n"
          ]
        }
      ],
      "source": [
        "# Ethos-U-Vela need to be installed this way, or SSCMA does not work anymore...\n",
        "!git clone https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git\n",
        "%cd ethos-u-vela\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git   #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wRJ2QHmMhT8"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qpQkgUioMhT8",
        "outputId": "a8b6e08f-e477-4da2-b31e-8f2e94da40e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-24 08:18:55--  https://files.seeedstudio.com/sscma/model_zoo/detection/person/person_detection.pth\n",
            "Resolving files.seeedstudio.com (files.seeedstudio.com)... 3.163.125.9, 3.163.125.51, 3.163.125.62, ...\n",
            "Connecting to files.seeedstudio.com (files.seeedstudio.com)|3.163.125.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23352107 (22M) [application/octet-stream]\n",
            "Saving to: ‘person_Detection_Swift-YOLO_192/pretrain.pth’\n",
            "\n",
            "person_Detection_Sw 100%[===================>]  22.27M  63.0MB/s    in 0.4s    \n",
            "\n",
            "2024-11-24 08:18:55 (63.0 MB/s) - ‘person_Detection_Swift-YOLO_192/pretrain.pth’ saved [23352107/23352107]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p person_Detection_Swift-YOLO_192\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/person/person_detection.pth -O person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTArXfttMhT8"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "klc9s8GHMhT9",
        "outputId": "a835aa35-5957-4142-f5ff-f332753fee6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-24 08:19:37--  https://universe.roboflow.com/ds/RFhocq9L2g?key=Ttmf6Fgq19\n",
            "Resolving universe.roboflow.com (universe.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n",
            "Connecting to universe.roboflow.com (universe.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-regional-exports/RAVDoTsolh1do3hIfXZU/DEc3HNT2qq4yi4GprKUh/7/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20241124%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20241124T081938Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=5bce15f5b4fae3f979562ce23ae973cbc2a3a7541e8f4bc41e120965f38f1dd8f37dba21746282fdde12e772ec4042ecefa30c14f2b593401254ef23a6e6b86178ab2b93d94a3caa646884c1e5e84664f33cf60fda3ee5bd7d1153f85b1a2c039844a8124f8f0088ce7e13b94d85b3f5ce89ff7fb8c18e5f4c8953e9f3427089c66d2e1c4d20552a492e279e1abb62bff08d31311542072a983390a7dc3ae2f168702e8588d9b07aad09d5e83fe62bf1c9d99dccd3f805ab811da19c561532ec87c83236ec61843987bd1eefe4a0a7be0991bff1f0cfa95001993b7c3703bae2029ed531f1f0f6fbbd9cb515f034e61757d54ba7dca7685d842d7f86cb560877 [following]\n",
            "--2024-11-24 08:19:38--  https://storage.googleapis.com/roboflow-platform-regional-exports/RAVDoTsolh1do3hIfXZU/DEc3HNT2qq4yi4GprKUh/7/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20241124%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20241124T081938Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=5bce15f5b4fae3f979562ce23ae973cbc2a3a7541e8f4bc41e120965f38f1dd8f37dba21746282fdde12e772ec4042ecefa30c14f2b593401254ef23a6e6b86178ab2b93d94a3caa646884c1e5e84664f33cf60fda3ee5bd7d1153f85b1a2c039844a8124f8f0088ce7e13b94d85b3f5ce89ff7fb8c18e5f4c8953e9f3427089c66d2e1c4d20552a492e279e1abb62bff08d31311542072a983390a7dc3ae2f168702e8588d9b07aad09d5e83fe62bf1c9d99dccd3f805ab811da19c561532ec87c83236ec61843987bd1eefe4a0a7be0991bff1f0cfa95001993b7c3703bae2029ed531f1f0f6fbbd9cb515f034e61757d54ba7dca7685d842d7f86cb560877\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.207, 142.250.101.207, 142.251.2.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52515037 (50M) [application/zip]\n",
            "Saving to: ‘person_Detection_Swift-YOLO_192/dataset.zip’\n",
            "\n",
            "person_Detection_Sw 100%[===================>]  50.08M  36.0MB/s    in 1.4s    \n",
            "\n",
            "2024-11-24 08:19:39 (36.0 MB/s) - ‘person_Detection_Swift-YOLO_192/dataset.zip’ saved [52515037/52515037]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p person_Detection_Swift-YOLO_192/dataset\n",
        "!wget -c https://universe.roboflow.com/ds/RFhocq9L2g?key=Ttmf6Fgq19 -O person_Detection_Swift-YOLO_192/dataset.zip\n",
        "!unzip -q person_Detection_Swift-YOLO_192/dataset.zip -d person_Detection_Swift-YOLO_192/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqUvNgvGMhT9"
      },
      "source": [
        "## 🚀Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OY7NRvfWMhT9",
        "outputId": "63d26fa2-58cf-4c42-f31f-945b762997e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "11/24 08:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1793242662\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.5\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1793242662\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "11/24 08:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'person_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'person_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.09000000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'person_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'person_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'person_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/person_Detection_Swift-YOLO_192/20241124_082607'}\n",
            "2024-11-24 08:26:10.071340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-24 08:26:10.091598: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-24 08:26:10.097444: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-24 08:26:10.111947: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-24 08:26:11.929788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "11/24 08:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "11/24 08:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[1, 3, 192, 192]\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::add encountered 24 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul encountered 18 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::meshgrid encountered 3 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::clone encountered 3 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sub encountered 3 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul_ encountered 6 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "bbox_head.head_module.data_preprocessor, bbox_head.loss_bbox, bbox_head.loss_cls, bbox_head.loss_obj, data_preprocessor\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 85 time(s)\n",
            "11/24 08:26:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::upsample_nearest2d encountered 2 time(s)\n",
            "\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "|\u001b[1m \u001b[0m\u001b[1mmodule                                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "| model                                        | 0.944M               | 0.125G     | 1.054M       |\n",
            "|  backbone                                    |  0.66M               |  0.101G    |  0.868M      |\n",
            "|   backbone.stem.conv                         |   1.76K              |   16.22M   |   0.147M     |\n",
            "|    backbone.stem.conv.conv                   |    1.728K            |    15.925M |    0.147M    |\n",
            "|    backbone.stem.conv.norm                   |    32                |    0.295M  |    0         |\n",
            "|   backbone.stage1                            |   9.216K             |   21.234M  |   0.332M     |\n",
            "|    backbone.stage1.0.conv                    |    3.504K            |    8.073M  |    55.296K   |\n",
            "|    backbone.stage1.1                         |    5.712K            |    13.16M  |    0.276M    |\n",
            "|   backbone.stage2                            |   36.56K             |   21.059M  |   0.207M     |\n",
            "|    backbone.stage2.0.conv                    |    8.72K             |    5.023M  |    23.04K    |\n",
            "|    backbone.stage2.1                         |    27.84K            |    16.036M |    0.184M    |\n",
            "|   backbone.stage3                            |   0.188M             |   27.003M  |   0.138M     |\n",
            "|    backbone.stage3.0.conv                    |    28.96K            |    4.17M   |    11.52K    |\n",
            "|    backbone.stage3.1                         |    0.159M            |    22.833M |    0.127M    |\n",
            "|   backbone.stage4                            |   0.425M             |   15.293M  |   43.2K      |\n",
            "|    backbone.stage4.0.conv                    |    0.116M            |    4.159M  |    5.76K     |\n",
            "|    backbone.stage4.1                         |    0.245M            |    8.813M  |    28.8K     |\n",
            "|    backbone.stage4.2                         |    64.48K            |    2.321M  |    8.64K     |\n",
            "|  neck                                        |  0.279M              |  23.881M   |  0.173M      |\n",
            "|   neck.reduce_layers.2.conv                  |   12.96K             |   0.467M   |   2.88K      |\n",
            "|    neck.reduce_layers.2.conv.conv            |    12.8K             |    0.461M  |    2.88K     |\n",
            "|    neck.reduce_layers.2.conv.norm            |    0.16K             |    5.76K   |    0         |\n",
            "|   neck.top_down_layers                       |   48K                |   10.817M  |   0.109M     |\n",
            "|    neck.top_down_layers.0                    |    38.96K            |    5.61M   |    40.32K    |\n",
            "|    neck.top_down_layers.1                    |    9.04K             |    5.207M  |    69.12K    |\n",
            "|   neck.downsample_layers                     |   72.24K             |   4.164M   |   8.64K      |\n",
            "|    neck.downsample_layers.0.conv             |    14.48K            |    2.085M  |    5.76K     |\n",
            "|    neck.downsample_layers.1.conv             |    57.76K            |    2.079M  |    2.88K     |\n",
            "|   neck.bottom_up_layers                      |   0.145M             |   8.398M   |   51.84K     |\n",
            "|    neck.bottom_up_layers.0                   |    29.28K            |    4.216M  |    34.56K    |\n",
            "|    neck.bottom_up_layers.1                   |    0.116M            |    4.182M  |    17.28K    |\n",
            "|   neck.upsample_layers                       |                      |   34.56K   |   0          |\n",
            "|    neck.upsample_layers.0                    |                      |    11.52K  |    0         |\n",
            "|    neck.upsample_layers.1                    |                      |    23.04K  |    0         |\n",
            "|  bbox_head.head_module.convs_pred            |  5.094K              |  0.726M    |  13.608K     |\n",
            "|   bbox_head.head_module.convs_pred.0         |   0.738K             |   0.415M   |   10.368K    |\n",
            "|    bbox_head.head_module.convs_pred.0.weight |    (18, 40, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module.convs_pred.0.bias   |    (18,)             |            |              |\n",
            "|   bbox_head.head_module.convs_pred.1         |   1.458K             |   0.207M   |   2.592K     |\n",
            "|    bbox_head.head_module.convs_pred.1.weight |    (18, 80, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module.convs_pred.1.bias   |    (18,)             |            |              |\n",
            "|   bbox_head.head_module.convs_pred.2         |   2.898K             |   0.104M   |   0.648K     |\n",
            "|    bbox_head.head_module.convs_pred.2.weight |    (18, 160, 1, 1)   |            |              |\n",
            "|    bbox_head.head_module.convs_pred.2.bias   |    (18,)             |            |              |\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "\n",
            "========================================\n",
            "    Input Shape     :  [1, 3, 192, 192]  \n",
            "    Model Flops     :       0.125G       \n",
            "  Model Parameters  :       0.944M       \n",
            "========================================\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "11/24 08:26:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 88 .bias, 88 conv.weight, 85 other\n",
            "Loads checkpoint by local backend from path: person_Detection_Swift-YOLO_192/pretrain.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.norm.weight, backbone.stage1.1.main_conv.norm.bias, backbone.stage1.1.main_conv.norm.running_mean, backbone.stage1.1.main_conv.norm.running_var, backbone.stage1.1.short_conv.norm.weight, backbone.stage1.1.short_conv.norm.bias, backbone.stage1.1.short_conv.norm.running_mean, backbone.stage1.1.short_conv.norm.running_var, backbone.stage1.1.final_conv.norm.weight, backbone.stage1.1.final_conv.norm.bias, backbone.stage1.1.final_conv.norm.running_mean, backbone.stage1.1.final_conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.norm.weight, backbone.stage1.1.blocks.0.conv1.norm.bias, backbone.stage1.1.blocks.0.conv1.norm.running_mean, backbone.stage1.1.blocks.0.conv1.norm.running_var, backbone.stage1.1.blocks.0.conv2.norm.weight, backbone.stage1.1.blocks.0.conv2.norm.bias, backbone.stage1.1.blocks.0.conv2.norm.running_mean, backbone.stage1.1.blocks.0.conv2.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.norm.weight, backbone.stage1.1.blocks.1.conv1.norm.bias, backbone.stage1.1.blocks.1.conv1.norm.running_mean, backbone.stage1.1.blocks.1.conv1.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.weight, backbone.stage1.1.blocks.1.conv2.norm.weight, backbone.stage1.1.blocks.1.conv2.norm.bias, backbone.stage1.1.blocks.1.conv2.norm.running_mean, backbone.stage1.1.blocks.1.conv2.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.weight, backbone.stage1.1.blocks.2.conv1.norm.weight, backbone.stage1.1.blocks.2.conv1.norm.bias, backbone.stage1.1.blocks.2.conv1.norm.running_mean, backbone.stage1.1.blocks.2.conv1.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.weight, backbone.stage1.1.blocks.2.conv2.norm.weight, backbone.stage1.1.blocks.2.conv2.norm.bias, backbone.stage1.1.blocks.2.conv2.norm.running_mean, backbone.stage1.1.blocks.2.conv2.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.norm.weight, backbone.stage2.1.main_conv.norm.bias, backbone.stage2.1.main_conv.norm.running_mean, backbone.stage2.1.main_conv.norm.running_var, backbone.stage2.1.short_conv.norm.weight, backbone.stage2.1.short_conv.norm.bias, backbone.stage2.1.short_conv.norm.running_mean, backbone.stage2.1.short_conv.norm.running_var, backbone.stage2.1.final_conv.norm.weight, backbone.stage2.1.final_conv.norm.bias, backbone.stage2.1.final_conv.norm.running_mean, backbone.stage2.1.final_conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.norm.weight, backbone.stage2.1.blocks.0.conv1.norm.bias, backbone.stage2.1.blocks.0.conv1.norm.running_mean, backbone.stage2.1.blocks.0.conv1.norm.running_var, backbone.stage2.1.blocks.0.conv2.norm.weight, backbone.stage2.1.blocks.0.conv2.norm.bias, backbone.stage2.1.blocks.0.conv2.norm.running_mean, backbone.stage2.1.blocks.0.conv2.norm.running_var, backbone.stage2.1.blocks.1.conv1.norm.weight, backbone.stage2.1.blocks.1.conv1.norm.bias, backbone.stage2.1.blocks.1.conv1.norm.running_mean, backbone.stage2.1.blocks.1.conv1.norm.running_var, backbone.stage2.1.blocks.1.conv2.norm.weight, backbone.stage2.1.blocks.1.conv2.norm.bias, backbone.stage2.1.blocks.1.conv2.norm.running_mean, backbone.stage2.1.blocks.1.conv2.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.norm.weight, backbone.stage2.1.blocks.2.conv1.norm.bias, backbone.stage2.1.blocks.2.conv1.norm.running_mean, backbone.stage2.1.blocks.2.conv1.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.weight, backbone.stage2.1.blocks.2.conv2.norm.weight, backbone.stage2.1.blocks.2.conv2.norm.bias, backbone.stage2.1.blocks.2.conv2.norm.running_mean, backbone.stage2.1.blocks.2.conv2.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.norm.weight, backbone.stage2.1.blocks.3.conv1.norm.bias, backbone.stage2.1.blocks.3.conv1.norm.running_mean, backbone.stage2.1.blocks.3.conv1.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.weight, backbone.stage2.1.blocks.3.conv2.norm.weight, backbone.stage2.1.blocks.3.conv2.norm.bias, backbone.stage2.1.blocks.3.conv2.norm.running_mean, backbone.stage2.1.blocks.3.conv2.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.weight, backbone.stage2.1.blocks.4.conv1.norm.weight, backbone.stage2.1.blocks.4.conv1.norm.bias, backbone.stage2.1.blocks.4.conv1.norm.running_mean, backbone.stage2.1.blocks.4.conv1.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.weight, backbone.stage2.1.blocks.4.conv2.norm.weight, backbone.stage2.1.blocks.4.conv2.norm.bias, backbone.stage2.1.blocks.4.conv2.norm.running_mean, backbone.stage2.1.blocks.4.conv2.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.weight, backbone.stage2.1.blocks.5.conv1.norm.weight, backbone.stage2.1.blocks.5.conv1.norm.bias, backbone.stage2.1.blocks.5.conv1.norm.running_mean, backbone.stage2.1.blocks.5.conv1.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.weight, backbone.stage2.1.blocks.5.conv2.norm.weight, backbone.stage2.1.blocks.5.conv2.norm.bias, backbone.stage2.1.blocks.5.conv2.norm.running_mean, backbone.stage2.1.blocks.5.conv2.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.norm.weight, backbone.stage3.1.main_conv.norm.bias, backbone.stage3.1.main_conv.norm.running_mean, backbone.stage3.1.main_conv.norm.running_var, backbone.stage3.1.short_conv.norm.weight, backbone.stage3.1.short_conv.norm.bias, backbone.stage3.1.short_conv.norm.running_mean, backbone.stage3.1.short_conv.norm.running_var, backbone.stage3.1.final_conv.norm.weight, backbone.stage3.1.final_conv.norm.bias, backbone.stage3.1.final_conv.norm.running_mean, backbone.stage3.1.final_conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.norm.weight, backbone.stage3.1.blocks.0.conv1.norm.bias, backbone.stage3.1.blocks.0.conv1.norm.running_mean, backbone.stage3.1.blocks.0.conv1.norm.running_var, backbone.stage3.1.blocks.0.conv2.norm.weight, backbone.stage3.1.blocks.0.conv2.norm.bias, backbone.stage3.1.blocks.0.conv2.norm.running_mean, backbone.stage3.1.blocks.0.conv2.norm.running_var, backbone.stage3.1.blocks.1.conv1.norm.weight, backbone.stage3.1.blocks.1.conv1.norm.bias, backbone.stage3.1.blocks.1.conv1.norm.running_mean, backbone.stage3.1.blocks.1.conv1.norm.running_var, backbone.stage3.1.blocks.1.conv2.norm.weight, backbone.stage3.1.blocks.1.conv2.norm.bias, backbone.stage3.1.blocks.1.conv2.norm.running_mean, backbone.stage3.1.blocks.1.conv2.norm.running_var, backbone.stage3.1.blocks.2.conv1.norm.weight, backbone.stage3.1.blocks.2.conv1.norm.bias, backbone.stage3.1.blocks.2.conv1.norm.running_mean, backbone.stage3.1.blocks.2.conv1.norm.running_var, backbone.stage3.1.blocks.2.conv2.norm.weight, backbone.stage3.1.blocks.2.conv2.norm.bias, backbone.stage3.1.blocks.2.conv2.norm.running_mean, backbone.stage3.1.blocks.2.conv2.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.norm.weight, backbone.stage3.1.blocks.3.conv1.norm.bias, backbone.stage3.1.blocks.3.conv1.norm.running_mean, backbone.stage3.1.blocks.3.conv1.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.weight, backbone.stage3.1.blocks.3.conv2.norm.weight, backbone.stage3.1.blocks.3.conv2.norm.bias, backbone.stage3.1.blocks.3.conv2.norm.running_mean, backbone.stage3.1.blocks.3.conv2.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.weight, backbone.stage3.1.blocks.4.conv1.norm.weight, backbone.stage3.1.blocks.4.conv1.norm.bias, backbone.stage3.1.blocks.4.conv1.norm.running_mean, backbone.stage3.1.blocks.4.conv1.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.weight, backbone.stage3.1.blocks.4.conv2.norm.weight, backbone.stage3.1.blocks.4.conv2.norm.bias, backbone.stage3.1.blocks.4.conv2.norm.running_mean, backbone.stage3.1.blocks.4.conv2.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.weight, backbone.stage3.1.blocks.5.conv1.norm.weight, backbone.stage3.1.blocks.5.conv1.norm.bias, backbone.stage3.1.blocks.5.conv1.norm.running_mean, backbone.stage3.1.blocks.5.conv1.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.weight, backbone.stage3.1.blocks.5.conv2.norm.weight, backbone.stage3.1.blocks.5.conv2.norm.bias, backbone.stage3.1.blocks.5.conv2.norm.running_mean, backbone.stage3.1.blocks.5.conv2.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.weight, backbone.stage3.1.blocks.6.conv1.norm.weight, backbone.stage3.1.blocks.6.conv1.norm.bias, backbone.stage3.1.blocks.6.conv1.norm.running_mean, backbone.stage3.1.blocks.6.conv1.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.weight, backbone.stage3.1.blocks.6.conv2.norm.weight, backbone.stage3.1.blocks.6.conv2.norm.bias, backbone.stage3.1.blocks.6.conv2.norm.running_mean, backbone.stage3.1.blocks.6.conv2.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.weight, backbone.stage3.1.blocks.7.conv1.norm.weight, backbone.stage3.1.blocks.7.conv1.norm.bias, backbone.stage3.1.blocks.7.conv1.norm.running_mean, backbone.stage3.1.blocks.7.conv1.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.weight, backbone.stage3.1.blocks.7.conv2.norm.weight, backbone.stage3.1.blocks.7.conv2.norm.bias, backbone.stage3.1.blocks.7.conv2.norm.running_mean, backbone.stage3.1.blocks.7.conv2.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.weight, backbone.stage3.1.blocks.8.conv1.norm.weight, backbone.stage3.1.blocks.8.conv1.norm.bias, backbone.stage3.1.blocks.8.conv1.norm.running_mean, backbone.stage3.1.blocks.8.conv1.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.weight, backbone.stage3.1.blocks.8.conv2.norm.weight, backbone.stage3.1.blocks.8.conv2.norm.bias, backbone.stage3.1.blocks.8.conv2.norm.running_mean, backbone.stage3.1.blocks.8.conv2.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.norm.weight, backbone.stage4.1.main_conv.norm.bias, backbone.stage4.1.main_conv.norm.running_mean, backbone.stage4.1.main_conv.norm.running_var, backbone.stage4.1.short_conv.norm.weight, backbone.stage4.1.short_conv.norm.bias, backbone.stage4.1.short_conv.norm.running_mean, backbone.stage4.1.short_conv.norm.running_var, backbone.stage4.1.final_conv.norm.weight, backbone.stage4.1.final_conv.norm.bias, backbone.stage4.1.final_conv.norm.running_mean, backbone.stage4.1.final_conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.norm.weight, backbone.stage4.1.blocks.0.conv1.norm.bias, backbone.stage4.1.blocks.0.conv1.norm.running_mean, backbone.stage4.1.blocks.0.conv1.norm.running_var, backbone.stage4.1.blocks.0.conv2.norm.weight, backbone.stage4.1.blocks.0.conv2.norm.bias, backbone.stage4.1.blocks.0.conv2.norm.running_mean, backbone.stage4.1.blocks.0.conv2.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.weight, backbone.stage4.1.blocks.1.conv1.norm.weight, backbone.stage4.1.blocks.1.conv1.norm.bias, backbone.stage4.1.blocks.1.conv1.norm.running_mean, backbone.stage4.1.blocks.1.conv1.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.weight, backbone.stage4.1.blocks.1.conv2.norm.weight, backbone.stage4.1.blocks.1.conv2.norm.bias, backbone.stage4.1.blocks.1.conv2.norm.running_mean, backbone.stage4.1.blocks.1.conv2.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.weight, backbone.stage4.1.blocks.2.conv1.norm.weight, backbone.stage4.1.blocks.2.conv1.norm.bias, backbone.stage4.1.blocks.2.conv1.norm.running_mean, backbone.stage4.1.blocks.2.conv1.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.weight, backbone.stage4.1.blocks.2.conv2.norm.weight, backbone.stage4.1.blocks.2.conv2.norm.bias, backbone.stage4.1.blocks.2.conv2.norm.running_mean, backbone.stage4.1.blocks.2.conv2.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.norm.weight, neck.top_down_layers.0.0.main_conv.norm.bias, neck.top_down_layers.0.0.main_conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.norm.running_var, neck.top_down_layers.0.0.short_conv.norm.weight, neck.top_down_layers.0.0.short_conv.norm.bias, neck.top_down_layers.0.0.short_conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.norm.running_var, neck.top_down_layers.0.0.final_conv.norm.weight, neck.top_down_layers.0.0.final_conv.norm.bias, neck.top_down_layers.0.0.final_conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.norm.weight, neck.top_down_layers.1.main_conv.norm.bias, neck.top_down_layers.1.main_conv.norm.running_mean, neck.top_down_layers.1.main_conv.norm.running_var, neck.top_down_layers.1.short_conv.norm.weight, neck.top_down_layers.1.short_conv.norm.bias, neck.top_down_layers.1.short_conv.norm.running_mean, neck.top_down_layers.1.short_conv.norm.running_var, neck.top_down_layers.1.final_conv.norm.weight, neck.top_down_layers.1.final_conv.norm.bias, neck.top_down_layers.1.final_conv.norm.running_mean, neck.top_down_layers.1.final_conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.norm.weight, neck.top_down_layers.1.blocks.0.conv1.norm.bias, neck.top_down_layers.1.blocks.0.conv1.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.norm.weight, neck.top_down_layers.1.blocks.0.conv2.norm.bias, neck.top_down_layers.1.blocks.0.conv2.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.norm.weight, neck.bottom_up_layers.0.main_conv.norm.bias, neck.bottom_up_layers.0.main_conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.norm.running_var, neck.bottom_up_layers.0.short_conv.norm.weight, neck.bottom_up_layers.0.short_conv.norm.bias, neck.bottom_up_layers.0.short_conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.norm.running_var, neck.bottom_up_layers.0.final_conv.norm.weight, neck.bottom_up_layers.0.final_conv.norm.bias, neck.bottom_up_layers.0.final_conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_var, neck.bottom_up_layers.1.main_conv.norm.weight, neck.bottom_up_layers.1.main_conv.norm.bias, neck.bottom_up_layers.1.main_conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.norm.running_var, neck.bottom_up_layers.1.short_conv.norm.weight, neck.bottom_up_layers.1.short_conv.norm.bias, neck.bottom_up_layers.1.short_conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.norm.running_var, neck.bottom_up_layers.1.final_conv.norm.weight, neck.bottom_up_layers.1.final_conv.norm.bias, neck.bottom_up_layers.1.final_conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_var\n",
            "\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.norm.weight, backbone.stage1.1.main_conv.norm.bias, backbone.stage1.1.main_conv.norm.running_mean, backbone.stage1.1.main_conv.norm.running_var, backbone.stage1.1.short_conv.norm.weight, backbone.stage1.1.short_conv.norm.bias, backbone.stage1.1.short_conv.norm.running_mean, backbone.stage1.1.short_conv.norm.running_var, backbone.stage1.1.final_conv.norm.weight, backbone.stage1.1.final_conv.norm.bias, backbone.stage1.1.final_conv.norm.running_mean, backbone.stage1.1.final_conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.norm.weight, backbone.stage1.1.blocks.0.conv1.norm.bias, backbone.stage1.1.blocks.0.conv1.norm.running_mean, backbone.stage1.1.blocks.0.conv1.norm.running_var, backbone.stage1.1.blocks.0.conv2.norm.weight, backbone.stage1.1.blocks.0.conv2.norm.bias, backbone.stage1.1.blocks.0.conv2.norm.running_mean, backbone.stage1.1.blocks.0.conv2.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.norm.weight, backbone.stage1.1.blocks.1.conv1.norm.bias, backbone.stage1.1.blocks.1.conv1.norm.running_mean, backbone.stage1.1.blocks.1.conv1.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.weight, backbone.stage1.1.blocks.1.conv2.norm.weight, backbone.stage1.1.blocks.1.conv2.norm.bias, backbone.stage1.1.blocks.1.conv2.norm.running_mean, backbone.stage1.1.blocks.1.conv2.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.weight, backbone.stage1.1.blocks.2.conv1.norm.weight, backbone.stage1.1.blocks.2.conv1.norm.bias, backbone.stage1.1.blocks.2.conv1.norm.running_mean, backbone.stage1.1.blocks.2.conv1.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.weight, backbone.stage1.1.blocks.2.conv2.norm.weight, backbone.stage1.1.blocks.2.conv2.norm.bias, backbone.stage1.1.blocks.2.conv2.norm.running_mean, backbone.stage1.1.blocks.2.conv2.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.norm.weight, backbone.stage2.1.main_conv.norm.bias, backbone.stage2.1.main_conv.norm.running_mean, backbone.stage2.1.main_conv.norm.running_var, backbone.stage2.1.short_conv.norm.weight, backbone.stage2.1.short_conv.norm.bias, backbone.stage2.1.short_conv.norm.running_mean, backbone.stage2.1.short_conv.norm.running_var, backbone.stage2.1.final_conv.norm.weight, backbone.stage2.1.final_conv.norm.bias, backbone.stage2.1.final_conv.norm.running_mean, backbone.stage2.1.final_conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.norm.weight, backbone.stage2.1.blocks.0.conv1.norm.bias, backbone.stage2.1.blocks.0.conv1.norm.running_mean, backbone.stage2.1.blocks.0.conv1.norm.running_var, backbone.stage2.1.blocks.0.conv2.norm.weight, backbone.stage2.1.blocks.0.conv2.norm.bias, backbone.stage2.1.blocks.0.conv2.norm.running_mean, backbone.stage2.1.blocks.0.conv2.norm.running_var, backbone.stage2.1.blocks.1.conv1.norm.weight, backbone.stage2.1.blocks.1.conv1.norm.bias, backbone.stage2.1.blocks.1.conv1.norm.running_mean, backbone.stage2.1.blocks.1.conv1.norm.running_var, backbone.stage2.1.blocks.1.conv2.norm.weight, backbone.stage2.1.blocks.1.conv2.norm.bias, backbone.stage2.1.blocks.1.conv2.norm.running_mean, backbone.stage2.1.blocks.1.conv2.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.norm.weight, backbone.stage2.1.blocks.2.conv1.norm.bias, backbone.stage2.1.blocks.2.conv1.norm.running_mean, backbone.stage2.1.blocks.2.conv1.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.weight, backbone.stage2.1.blocks.2.conv2.norm.weight, backbone.stage2.1.blocks.2.conv2.norm.bias, backbone.stage2.1.blocks.2.conv2.norm.running_mean, backbone.stage2.1.blocks.2.conv2.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.norm.weight, backbone.stage2.1.blocks.3.conv1.norm.bias, backbone.stage2.1.blocks.3.conv1.norm.running_mean, backbone.stage2.1.blocks.3.conv1.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.weight, backbone.stage2.1.blocks.3.conv2.norm.weight, backbone.stage2.1.blocks.3.conv2.norm.bias, backbone.stage2.1.blocks.3.conv2.norm.running_mean, backbone.stage2.1.blocks.3.conv2.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.weight, backbone.stage2.1.blocks.4.conv1.norm.weight, backbone.stage2.1.blocks.4.conv1.norm.bias, backbone.stage2.1.blocks.4.conv1.norm.running_mean, backbone.stage2.1.blocks.4.conv1.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.weight, backbone.stage2.1.blocks.4.conv2.norm.weight, backbone.stage2.1.blocks.4.conv2.norm.bias, backbone.stage2.1.blocks.4.conv2.norm.running_mean, backbone.stage2.1.blocks.4.conv2.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.weight, backbone.stage2.1.blocks.5.conv1.norm.weight, backbone.stage2.1.blocks.5.conv1.norm.bias, backbone.stage2.1.blocks.5.conv1.norm.running_mean, backbone.stage2.1.blocks.5.conv1.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.weight, backbone.stage2.1.blocks.5.conv2.norm.weight, backbone.stage2.1.blocks.5.conv2.norm.bias, backbone.stage2.1.blocks.5.conv2.norm.running_mean, backbone.stage2.1.blocks.5.conv2.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.norm.weight, backbone.stage3.1.main_conv.norm.bias, backbone.stage3.1.main_conv.norm.running_mean, backbone.stage3.1.main_conv.norm.running_var, backbone.stage3.1.short_conv.norm.weight, backbone.stage3.1.short_conv.norm.bias, backbone.stage3.1.short_conv.norm.running_mean, backbone.stage3.1.short_conv.norm.running_var, backbone.stage3.1.final_conv.norm.weight, backbone.stage3.1.final_conv.norm.bias, backbone.stage3.1.final_conv.norm.running_mean, backbone.stage3.1.final_conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.norm.weight, backbone.stage3.1.blocks.0.conv1.norm.bias, backbone.stage3.1.blocks.0.conv1.norm.running_mean, backbone.stage3.1.blocks.0.conv1.norm.running_var, backbone.stage3.1.blocks.0.conv2.norm.weight, backbone.stage3.1.blocks.0.conv2.norm.bias, backbone.stage3.1.blocks.0.conv2.norm.running_mean, backbone.stage3.1.blocks.0.conv2.norm.running_var, backbone.stage3.1.blocks.1.conv1.norm.weight, backbone.stage3.1.blocks.1.conv1.norm.bias, backbone.stage3.1.blocks.1.conv1.norm.running_mean, backbone.stage3.1.blocks.1.conv1.norm.running_var, backbone.stage3.1.blocks.1.conv2.norm.weight, backbone.stage3.1.blocks.1.conv2.norm.bias, backbone.stage3.1.blocks.1.conv2.norm.running_mean, backbone.stage3.1.blocks.1.conv2.norm.running_var, backbone.stage3.1.blocks.2.conv1.norm.weight, backbone.stage3.1.blocks.2.conv1.norm.bias, backbone.stage3.1.blocks.2.conv1.norm.running_mean, backbone.stage3.1.blocks.2.conv1.norm.running_var, backbone.stage3.1.blocks.2.conv2.norm.weight, backbone.stage3.1.blocks.2.conv2.norm.bias, backbone.stage3.1.blocks.2.conv2.norm.running_mean, backbone.stage3.1.blocks.2.conv2.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.norm.weight, backbone.stage3.1.blocks.3.conv1.norm.bias, backbone.stage3.1.blocks.3.conv1.norm.running_mean, backbone.stage3.1.blocks.3.conv1.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.weight, backbone.stage3.1.blocks.3.conv2.norm.weight, backbone.stage3.1.blocks.3.conv2.norm.bias, backbone.stage3.1.blocks.3.conv2.norm.running_mean, backbone.stage3.1.blocks.3.conv2.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.weight, backbone.stage3.1.blocks.4.conv1.norm.weight, backbone.stage3.1.blocks.4.conv1.norm.bias, backbone.stage3.1.blocks.4.conv1.norm.running_mean, backbone.stage3.1.blocks.4.conv1.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.weight, backbone.stage3.1.blocks.4.conv2.norm.weight, backbone.stage3.1.blocks.4.conv2.norm.bias, backbone.stage3.1.blocks.4.conv2.norm.running_mean, backbone.stage3.1.blocks.4.conv2.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.weight, backbone.stage3.1.blocks.5.conv1.norm.weight, backbone.stage3.1.blocks.5.conv1.norm.bias, backbone.stage3.1.blocks.5.conv1.norm.running_mean, backbone.stage3.1.blocks.5.conv1.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.weight, backbone.stage3.1.blocks.5.conv2.norm.weight, backbone.stage3.1.blocks.5.conv2.norm.bias, backbone.stage3.1.blocks.5.conv2.norm.running_mean, backbone.stage3.1.blocks.5.conv2.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.weight, backbone.stage3.1.blocks.6.conv1.norm.weight, backbone.stage3.1.blocks.6.conv1.norm.bias, backbone.stage3.1.blocks.6.conv1.norm.running_mean, backbone.stage3.1.blocks.6.conv1.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.weight, backbone.stage3.1.blocks.6.conv2.norm.weight, backbone.stage3.1.blocks.6.conv2.norm.bias, backbone.stage3.1.blocks.6.conv2.norm.running_mean, backbone.stage3.1.blocks.6.conv2.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.weight, backbone.stage3.1.blocks.7.conv1.norm.weight, backbone.stage3.1.blocks.7.conv1.norm.bias, backbone.stage3.1.blocks.7.conv1.norm.running_mean, backbone.stage3.1.blocks.7.conv1.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.weight, backbone.stage3.1.blocks.7.conv2.norm.weight, backbone.stage3.1.blocks.7.conv2.norm.bias, backbone.stage3.1.blocks.7.conv2.norm.running_mean, backbone.stage3.1.blocks.7.conv2.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.weight, backbone.stage3.1.blocks.8.conv1.norm.weight, backbone.stage3.1.blocks.8.conv1.norm.bias, backbone.stage3.1.blocks.8.conv1.norm.running_mean, backbone.stage3.1.blocks.8.conv1.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.weight, backbone.stage3.1.blocks.8.conv2.norm.weight, backbone.stage3.1.blocks.8.conv2.norm.bias, backbone.stage3.1.blocks.8.conv2.norm.running_mean, backbone.stage3.1.blocks.8.conv2.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.norm.weight, backbone.stage4.1.main_conv.norm.bias, backbone.stage4.1.main_conv.norm.running_mean, backbone.stage4.1.main_conv.norm.running_var, backbone.stage4.1.short_conv.norm.weight, backbone.stage4.1.short_conv.norm.bias, backbone.stage4.1.short_conv.norm.running_mean, backbone.stage4.1.short_conv.norm.running_var, backbone.stage4.1.final_conv.norm.weight, backbone.stage4.1.final_conv.norm.bias, backbone.stage4.1.final_conv.norm.running_mean, backbone.stage4.1.final_conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.norm.weight, backbone.stage4.1.blocks.0.conv1.norm.bias, backbone.stage4.1.blocks.0.conv1.norm.running_mean, backbone.stage4.1.blocks.0.conv1.norm.running_var, backbone.stage4.1.blocks.0.conv2.norm.weight, backbone.stage4.1.blocks.0.conv2.norm.bias, backbone.stage4.1.blocks.0.conv2.norm.running_mean, backbone.stage4.1.blocks.0.conv2.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.weight, backbone.stage4.1.blocks.1.conv1.norm.weight, backbone.stage4.1.blocks.1.conv1.norm.bias, backbone.stage4.1.blocks.1.conv1.norm.running_mean, backbone.stage4.1.blocks.1.conv1.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.weight, backbone.stage4.1.blocks.1.conv2.norm.weight, backbone.stage4.1.blocks.1.conv2.norm.bias, backbone.stage4.1.blocks.1.conv2.norm.running_mean, backbone.stage4.1.blocks.1.conv2.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.weight, backbone.stage4.1.blocks.2.conv1.norm.weight, backbone.stage4.1.blocks.2.conv1.norm.bias, backbone.stage4.1.blocks.2.conv1.norm.running_mean, backbone.stage4.1.blocks.2.conv1.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.weight, backbone.stage4.1.blocks.2.conv2.norm.weight, backbone.stage4.1.blocks.2.conv2.norm.bias, backbone.stage4.1.blocks.2.conv2.norm.running_mean, backbone.stage4.1.blocks.2.conv2.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.norm.weight, neck.top_down_layers.0.0.main_conv.norm.bias, neck.top_down_layers.0.0.main_conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.norm.running_var, neck.top_down_layers.0.0.short_conv.norm.weight, neck.top_down_layers.0.0.short_conv.norm.bias, neck.top_down_layers.0.0.short_conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.norm.running_var, neck.top_down_layers.0.0.final_conv.norm.weight, neck.top_down_layers.0.0.final_conv.norm.bias, neck.top_down_layers.0.0.final_conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.norm.weight, neck.top_down_layers.1.main_conv.norm.bias, neck.top_down_layers.1.main_conv.norm.running_mean, neck.top_down_layers.1.main_conv.norm.running_var, neck.top_down_layers.1.short_conv.norm.weight, neck.top_down_layers.1.short_conv.norm.bias, neck.top_down_layers.1.short_conv.norm.running_mean, neck.top_down_layers.1.short_conv.norm.running_var, neck.top_down_layers.1.final_conv.norm.weight, neck.top_down_layers.1.final_conv.norm.bias, neck.top_down_layers.1.final_conv.norm.running_mean, neck.top_down_layers.1.final_conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.norm.weight, neck.top_down_layers.1.blocks.0.conv1.norm.bias, neck.top_down_layers.1.blocks.0.conv1.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.norm.weight, neck.top_down_layers.1.blocks.0.conv2.norm.bias, neck.top_down_layers.1.blocks.0.conv2.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.norm.weight, neck.bottom_up_layers.0.main_conv.norm.bias, neck.bottom_up_layers.0.main_conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.norm.running_var, neck.bottom_up_layers.0.short_conv.norm.weight, neck.bottom_up_layers.0.short_conv.norm.bias, neck.bottom_up_layers.0.short_conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.norm.running_var, neck.bottom_up_layers.0.final_conv.norm.weight, neck.bottom_up_layers.0.final_conv.norm.bias, neck.bottom_up_layers.0.final_conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_var, neck.bottom_up_layers.1.main_conv.norm.weight, neck.bottom_up_layers.1.main_conv.norm.bias, neck.bottom_up_layers.1.main_conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.norm.running_var, neck.bottom_up_layers.1.short_conv.norm.weight, neck.bottom_up_layers.1.short_conv.norm.bias, neck.bottom_up_layers.1.short_conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.norm.running_var, neck.bottom_up_layers.1.final_conv.norm.weight, neck.bottom_up_layers.1.final_conv.norm.bias, neck.bottom_up_layers.1.final_conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_var\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      1/10     1.8421     0.0      0.4597    1.3824   0:10:16  : 100%|█████████| 336/336 [01:06<00:00,  5.06it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      2/10     1.5275     0.0      0.3985    1.1289   0:08:57  : 100%|█████████| 336/336 [01:05<00:00,  5.13it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      3/10     1.3707     0.0      0.3765    0.9942   0:07:46  : 100%|█████████| 336/336 [01:05<00:00,  5.15it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      4/10     1.2555     0.0      0.3618    0.8937   0:06:36  : 100%|█████████| 336/336 [01:03<00:00,  5.27it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      5/10     1.1934     0.0      0.3566    0.8368   0:05:30  : 100%|█████████| 336/336 [01:05<00:00,  5.09it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time      eta    \n",
            "   val       5/10     0.0239    0.155    0:00:00  : 100%|███████████████████████████████| 59/59 [00:07<00:00,  7.83it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.71s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.83s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.687\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      6/10     1.1284     0.0      0.3403    0.7881   0:04:26  : 100%|█████████| 336/336 [01:08<00:00,  4.88it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      7/10     1.0889     0.0      0.3322    0.7567   0:03:19  : 100%|█████████| 336/336 [01:05<00:00,  5.15it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      8/10     1.061      0.0      0.3303    0.7307   0:02:14  : 100%|█████████| 336/336 [01:10<00:00,  4.74it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      9/10     1.0221     0.0      0.3179    0.7042   0:01:06  : 100%|█████████| 336/336 [01:05<00:00,  5.16it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     10/10     0.9948     0.0      0.3111    0.6837   0:00:00  : 100%|█████████| 336/336 [01:09<00:00,  4.81it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      10/10     0.0084    0.1268    0.347     0.687     0.304     0.001     0.261     0.491    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.91s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.83s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.832\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745\n"
          ]
        }
      ],
      "source": [
        "!sscma.train configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=person_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=person_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sppupK9cMhT9"
      },
      "source": [
        "## 📦Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OoPR8hmnMhT9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('person_Detection_Swift-YOLO_192/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yf_pNq01MhT-",
        "outputId": "66f06468-6fa2-41e2-ccf1-3ae9ab21bc1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input type (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): image\n",
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "11/24 08:48:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1984629541\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.5\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1984629541\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "11/24 08:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'person_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "load_from = 'person_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.09000000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'person_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'person_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'person_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/person_Detection_Swift-YOLO_192/20241124_084858'}\n",
            "2024-11-24 08:49:01.767539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-24 08:49:01.801278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-24 08:49:01.809450: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-24 08:49:01.831400: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-24 08:49:03.543787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "11/24 08:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "11/24 08:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "100%|███████████| 100/100 [00:11<00:00,  8.34it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:1209: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n",
            "/content/ModelAssistant/person_Detection_Swift-YOLO_192/yolodetector_q.py:1043: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_0_f = torch.as_tensor(8, dtype=torch.float32, device=device_1_f)\n",
            "/content/ModelAssistant/person_Detection_Swift-YOLO_192/yolodetector_q.py:1114: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_1_f = torch.as_tensor(16, dtype=torch.float32, device=device_3_f)\n",
            "/content/ModelAssistant/person_Detection_Swift-YOLO_192/yolodetector_q.py:1185: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_2_f = torch.as_tensor(32, dtype=torch.float32, device=device_5_f)\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1616 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1625 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1662 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1670 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1706 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1714 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_int8.tflite\n",
            "Warning: No configuration file specified. Using a default of ['/usr/local/lib/python3.10/dist-packages/ethosu/config_files/Arm/vela.ini']. Compilation may be invalid or non-optimal.\n",
            "Warning: No system configuration specified. Using a default of Ethos_U55_High_End_Embedded. Compilation may be invalid or non-optimal.\n",
            "Warning: No memory mode specified. Using a default of Shared_Sram. Compilation may be invalid or non-optimal.\n",
            "Warning: TRANSPOSE 'contiguous_0_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 6, 576] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2853' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 24, 24, 18] and permutation is: [0 3 1 2]\n",
            "Info: PADV2 'input.37_transform_2' is a CPU only op\n",
            "Info: PADV2 'input.39_transform_2' is a CPU only op\n",
            "Info: PADV2 '2676_transform_2' is a CPU only op\n",
            "Warning: TRANSPOSE 'contiguous_1_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 6, 144] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2858' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 12, 12, 18] and permutation is: [0 3 1 2]\n",
            "Warning: TRANSPOSE 'contiguous_2_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 6, 36] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2863' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 6, 6, 18] and permutation is: [0 3 1 2]\n",
            "\n",
            "Network summary for epoch_10_int8\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration             Ethos_U55_High_End_Embedded\n",
            "Memory mode                               Shared_Sram\n",
            "Accelerator clock                                 500 MHz\n",
            "Design peak SRAM bandwidth                       3.73 GB/s\n",
            "Design peak Off-chip Flash bandwidth             0.47 GB/s\n",
            "\n",
            "Total SRAM used                                259.02 KiB\n",
            "Total Off-chip Flash used                     1162.77 KiB\n",
            "\n",
            "CPU operators = 9 (4.6%)\n",
            "NPU operators = 187 (95.4%)\n",
            "\n",
            "Average SRAM bandwidth                           0.80 GB/s\n",
            "Input   SRAM bandwidth                           3.64 MB/batch\n",
            "Weight  SRAM bandwidth                           5.30 MB/batch\n",
            "Output  SRAM bandwidth                           2.09 MB/batch\n",
            "Total   SRAM bandwidth                          11.07 MB/batch\n",
            "Total   SRAM bandwidth            per input     11.07 MB/inference (batch size 1)\n",
            "\n",
            "Average Off-chip Flash bandwidth                 0.08 GB/s\n",
            "Input   Off-chip Flash bandwidth                 0.07 MB/batch\n",
            "Weight  Off-chip Flash bandwidth                 1.06 MB/batch\n",
            "Output  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth                 1.13 MB/batch\n",
            "Total   Off-chip Flash bandwidth  per input      1.13 MB/inference (batch size 1)\n",
            "\n",
            "Neural network macs                         134443080 MACs/batch\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_int8.tflite\n",
            "/content/ModelAssistant/sscma/models/heads/yolov5_head.py:125: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  xy = (feat_xy * 2 - 0.5 + grid) * torch.as_tensor(\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float32.tflite\n",
            "Warning: No configuration file specified. Using a default of ['/usr/local/lib/python3.10/dist-packages/ethosu/config_files/Arm/vela.ini']. Compilation may be invalid or non-optimal.\n",
            "Warning: No system configuration specified. Using a default of Ethos_U55_High_End_Embedded. Compilation may be invalid or non-optimal.\n",
            "Warning: No memory mode specified. Using a default of Shared_Sram. Compilation may be invalid or non-optimal.\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '668_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: inputs.1, fuse_attr_319_reshape, 668_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '668_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform, 668_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '668_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform_1_te_transform_2, fuse_attr_320_reshape, 668_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '702_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform_1, fuse_attr_322_reshape, 702_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '737_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 702_te_transform_1, fuse_attr_323_reshape, 737_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_33'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 737_te_transform, fuse_attr_324_reshape, fuse_transform_33\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_35'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_33, 702_te_transform_1, fuse_transform_35\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '770_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_35, fuse_attr_325_reshape, 770_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_51'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 770_te_transform, fuse_attr_326_reshape, fuse_transform_51\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_53'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_51, fuse_transform_35, fuse_transform_53\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '803_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_53, fuse_attr_327_reshape, 803_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_54'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 803_te_transform, fuse_attr_328_reshape, fuse_transform_54\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_57'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_54, fuse_transform_53, fuse_transform_57\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_58'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform_1, fuse_attr_321_reshape, fuse_transform_58\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '821_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_58, 821_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '839_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 821_te_transform, fuse_attr_329_reshape, 839_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '839_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform, 839_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '839_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform_1_te_transform_2, fuse_attr_330_reshape, 839_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '873_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform_1, fuse_attr_332_reshape, 873_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '911_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 873_te_transform_1, fuse_attr_333_reshape, 911_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_81'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 911_te_transform, fuse_attr_334_reshape, fuse_transform_81\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_83'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_81, 873_te_transform_1, fuse_transform_83\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '944_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_83, fuse_attr_335_reshape, 944_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_92'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 944_te_transform, fuse_attr_336_reshape, fuse_transform_92\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_94'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_92, fuse_transform_83, fuse_transform_94\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '977_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_94, fuse_attr_337_reshape, 977_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_107'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 977_te_transform, fuse_attr_338_reshape, fuse_transform_107\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_109'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_107, fuse_transform_94, fuse_transform_109\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1010_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_109, fuse_attr_339_reshape, 1010_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_112'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1010_te_transform, fuse_attr_340_reshape, fuse_transform_112\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_114'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_112, fuse_transform_109, fuse_transform_114\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1043_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_114, fuse_attr_341_reshape, 1043_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_21'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1043_te_transform, fuse_attr_342_reshape, fuse_transform_21\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_23'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_21, fuse_transform_114, fuse_transform_23\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1076_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_23, fuse_attr_343_reshape, 1076_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_24'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1076_te_transform, fuse_attr_344_reshape, fuse_transform_24\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_27'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_24, fuse_transform_23, fuse_transform_27\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_28'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform_1, fuse_attr_331_reshape, fuse_transform_28\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1094_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_28, 1094_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1094_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1094_te_transform, fuse_attr_345_reshape, 1094_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1112_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1094_te_transform_1, 1112_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1112_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1112_te_transform_1_te_transform_2, fuse_attr_346_reshape, 1112_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1146_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1112_te_transform_1, fuse_attr_348_reshape, 1146_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1187_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1146_te_transform_1, fuse_attr_349_reshape, 1187_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_42'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1187_te_transform, fuse_attr_350_reshape, fuse_transform_42\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_44'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_42, 1146_te_transform_1, fuse_transform_44\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1220_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_44, fuse_attr_351_reshape, 1220_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_60'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1220_te_transform, fuse_attr_352_reshape, fuse_transform_60\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_62'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_60, fuse_transform_44, fuse_transform_62\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1253_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_62, fuse_attr_353_reshape, 1253_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_69'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1253_te_transform, fuse_attr_354_reshape, fuse_transform_69\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_71'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_69, fuse_transform_62, fuse_transform_71\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1286_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_71, fuse_attr_355_reshape, 1286_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_75'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1286_te_transform, fuse_attr_356_reshape, fuse_transform_75\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_77'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_75, fuse_transform_71, fuse_transform_77\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1319_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_77, fuse_attr_357_reshape, 1319_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_84'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1319_te_transform, fuse_attr_358_reshape, fuse_transform_84\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_86'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_84, fuse_transform_77, fuse_transform_86\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1352_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_86, fuse_attr_359_reshape, 1352_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_95'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1352_te_transform, fuse_attr_360_reshape, fuse_transform_95\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_97'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_95, fuse_transform_86, fuse_transform_97\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1385_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_97, fuse_attr_361_reshape, 1385_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_101'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1385_te_transform, fuse_attr_362_reshape, fuse_transform_101\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_103'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_101, fuse_transform_97, fuse_transform_103\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1418_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_103, fuse_attr_363_reshape, 1418_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_120'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1418_te_transform, fuse_attr_364_reshape, fuse_transform_120\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_122'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_120, fuse_transform_103, fuse_transform_122\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1451_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_122, fuse_attr_365_reshape, 1451_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_146'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1451_te_transform, fuse_attr_366_reshape, fuse_transform_146\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_18'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_146, fuse_transform_122, fuse_transform_18\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_19'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1112_te_transform_1, fuse_attr_347_reshape, fuse_transform_19\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1469_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_19, 1469_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1469_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1469_te_transform, fuse_attr_367_reshape, 1469_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1488_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1469_te_transform_1, 1488_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1488_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1488_te_transform_1_te_transform_2, fuse_attr_368_reshape, 1488_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1522_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1488_te_transform_1, fuse_attr_370_reshape, 1522_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1557_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1522_te_transform_1, fuse_attr_371_reshape, 1557_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_36'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1557_te_transform, fuse_attr_372_reshape, fuse_transform_36\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_38'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_36, 1522_te_transform_1, fuse_transform_38\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1590_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_38, fuse_attr_373_reshape, 1590_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_48'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1590_te_transform, fuse_attr_374_reshape, fuse_transform_48\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_50'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_48, fuse_transform_38, fuse_transform_50\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1623_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_50, fuse_attr_375_reshape, 1623_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_63'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1623_te_transform, fuse_attr_376_reshape, fuse_transform_63\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_66'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_63, fuse_transform_50, fuse_transform_66\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_67'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1488_te_transform_1, fuse_attr_369_reshape, fuse_transform_67\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1641_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_67, 1641_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1660_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1641_te_transform, fuse_attr_377_reshape, 1660_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1660_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1660_te_transform, fuse_attr_378_reshape, 1660_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'input.39_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1660_te_transform_1, input.39_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'input.49_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.39_transform_1, input.49_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'fuse_transform_90'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.49_transform_1, fuse_transform_90\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1693_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.39_transform_1, input.49_transform_1, 1693_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1747_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1693_te_transform, fuse_attr_379_reshape, 1747_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1747_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1747_te_transform, fuse_attr_380_reshape, 1747_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESIZE_NEAREST_NEIGHBOR 'fuse_transform_104'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1747_te_transform_1, fuse_transform_104\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_106'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1469_te_transform_1, fuse_transform_106\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1805_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_106, fuse_attr_382_reshape, 1805_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1820_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1805_te_transform, fuse_attr_383_reshape, 1820_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_117'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1820_te_transform, fuse_attr_384_reshape, fuse_transform_117\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_118'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_106, fuse_attr_381_reshape, fuse_transform_118\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1837_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_118, 1837_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1853_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1837_te_transform, fuse_attr_385_reshape, 1853_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1853_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1853_te_transform, fuse_attr_386_reshape, 1853_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESIZE_NEAREST_NEIGHBOR 'fuse_transform_30'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1853_te_transform_1, fuse_transform_30\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_32'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1094_te_transform_1, fuse_transform_32\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1909_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_32, fuse_attr_388_reshape, 1909_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1924_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1909_te_transform, fuse_attr_389_reshape, 1924_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_39'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1924_te_transform, fuse_attr_390_reshape, fuse_transform_39\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_40'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_32, fuse_attr_387_reshape, fuse_transform_40\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1941_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_40, 1941_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1941_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1941_te_transform, fuse_attr_391_reshape, 1941_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_110'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1941_te_transform_1, fuse_attr_404_reshape, fuse_transform_110\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_111'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_110, fuse_transform_111\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map.9, pred_map0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '268:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_.1, 268:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2571'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 268:0, 2570, 2571\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2573'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2571, 2572, 2573\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '282'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2573, grid.1, 282\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 282, 2574, xy.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 268:1, 2576, wh.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh.1, wh.1, wh0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh0.1, grid_.1, wh1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 268:2, 2578, cls.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh1.1, cls.1, out.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '313'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out.1, 313\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1957_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1941_te_transform_1, 1957_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_45'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1957_te_transform_1_te_transform_2, fuse_attr_392_reshape, fuse_transform_45\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_47'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1853_te_transform_1, fuse_transform_47\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2011_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_47, fuse_attr_394_reshape, 2011_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2026_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2011_te_transform, fuse_attr_395_reshape, 2026_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_72'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2026_te_transform, fuse_attr_396_reshape, fuse_transform_72\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_73'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_47, fuse_attr_393_reshape, fuse_transform_73\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2043_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_73, 2043_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2043_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2043_te_transform, fuse_attr_397_reshape, 2043_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_115'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2043_te_transform_1, fuse_attr_405_reshape, fuse_transform_115\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_116'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_115, fuse_transform_116\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map2.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map1.1, pred_map2.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '407:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_0.1, 407:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2581'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 407:0, 2580, 2581\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2583'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2581, 2582, 2583\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '421'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2583, grid0.1, 421\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 421, 2584, xy0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh2.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 407:1, 2586, wh2.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh3.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh2.1, wh2.1, wh3.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh4.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh3.1, grid_0.1, wh4.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 407:2, 2588, cls0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh4.1, cls0.1, out0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '452'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out0.1, 452\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '2059_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2043_te_transform_1, 2059_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_78'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2059_te_transform_1_te_transform_2, fuse_attr_398_reshape, fuse_transform_78\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_80'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1747_te_transform_1, fuse_transform_80\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2113_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_80, fuse_attr_400_reshape, 2113_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2128_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2113_te_transform, fuse_attr_401_reshape, 2128_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_98'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2128_te_transform, fuse_attr_402_reshape, fuse_transform_98\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_99'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_80, fuse_attr_399_reshape, fuse_transform_99\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2145_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_99, 2145_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'pred_map.1_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2145_te_transform, fuse_attr_403_reshape, pred_map.1_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_123'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map.1_te_transform, fuse_attr_406_reshape, fuse_transform_123\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_124'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_123, fuse_transform_124\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map4.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map3.1, pred_map4.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '546:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_1.1, 546:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2591'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 546:0, 2590, 2591\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2593'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2591, 2592, 2593\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '560'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2593, grid1.1, 560\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 560, 2594, xy1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh5.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 546:1, 2596, wh5.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh6.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh5.1, wh5.1, wh6.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh7.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh6.1, grid_1.1, wh7.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 546:2, 2598, cls1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh7.1, cls1.1, out1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '593'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out1.1, 593\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '596'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 452, 593, 596\n",
            "Warning: TRANSPOSE 'feat_.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map0.1' has data type: float32, Tensor 'feat_.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map.9' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_111' has data type: float32, Tensor 'pred_map.9' has data type: float32\n",
            "Warning: TRANSPOSE 'feat_0.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map2.1' has data type: float32, Tensor 'feat_0.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map1.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_116' has data type: float32, Tensor 'pred_map1.1' has data type: float32\n",
            "Warning: TRANSPOSE 'feat_1.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map4.1' has data type: float32, Tensor 'feat_1.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map3.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_124' has data type: float32, Tensor 'pred_map3.1' has data type: float32\n",
            "\n",
            "Network summary for epoch_10_float32\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration             Ethos_U55_High_End_Embedded\n",
            "Memory mode                               Shared_Sram\n",
            "Accelerator clock                                 500 MHz\n",
            "\n",
            "\n",
            "CPU operators = 179 (100.0%)\n",
            "NPU operators = 0 (0.0%)\n",
            "\n",
            "Neural network macs                                 0 MACs/batch\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float32.tflite\n",
            "ONNX: Ignoring unsupported precision: int8\n",
            "Exported graph: graph(%input : Float(1, 3, 192, 192, strides=[110592, 36864, 192, 1], requires_grad=0, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.weight : Float(18, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.bias : Float(18, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.weight : Float(18, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.bias : Float(18, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.weight : Float(18, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.bias : Float(18, strides=[1], requires_grad=1, device=cpu),\n",
            "      %onnx::Conv_1102 : Float(16, 3, 6, 6, strides=[108, 36, 6, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1103 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1105 : Float(24, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1106 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1108 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1109 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1111 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1112 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1114 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1115 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1117 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1118 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1120 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1121 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1123 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1124 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1126 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1127 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1129 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1130 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1132 : Float(24, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1133 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1135 : Float(40, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1136 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1138 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1139 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1141 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1142 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1144 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1145 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1147 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1148 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1150 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1151 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1153 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1154 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1156 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1157 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1159 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1160 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1162 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1163 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1165 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1166 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1168 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1169 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1171 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1172 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1174 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1175 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1177 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1178 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1180 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1181 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1183 : Float(80, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1184 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1186 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1187 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1189 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1190 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1192 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1193 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1195 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1196 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1198 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1199 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1201 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1202 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1204 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1205 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1207 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1208 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1210 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1211 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1213 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1214 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1216 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1217 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1219 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1220 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1222 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1223 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1225 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1226 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1228 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1229 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1231 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1232 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1234 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1235 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1237 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1238 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1240 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1241 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1243 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1244 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1246 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1247 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1249 : Float(160, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1250 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1252 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1253 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1255 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1256 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1258 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1259 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1261 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1262 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1264 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1265 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1267 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1268 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1270 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1271 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1273 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1274 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1276 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1277 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1279 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1280 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1282 : Float(160, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1283 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1285 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1286 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1288 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1289 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1291 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1292 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1294 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1295 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1297 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1298 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1300 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1301 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1303 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1304 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1306 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1307 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1309 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1310 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1312 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1313 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1315 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1316 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1318 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1319 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1321 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1322 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1324 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1325 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1327 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1328 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1330 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1331 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1333 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1334 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1336 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1337 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1339 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1340 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1342 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1343 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1345 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1346 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1348 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1349 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1351 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1352 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1354 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1355 : Float(160, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %/backbone/stem/conv/conv/Conv_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[6, 6], pads=[2, 2, 2, 2], strides=[2, 2], onnx_name=\"/backbone/stem/conv/conv/Conv\"](%input, %onnx::Conv_1102, %onnx::Conv_1103), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/sscma.models.base.conv_module.ConvModule::stem/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stem/conv/act/Relu_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stem/conv/act/Relu\"](%/backbone/stem/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/sscma.models.base.conv_module.ConvModule::stem/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.0/conv/conv/Conv_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage1/stage1.0/conv/conv/Conv\"](%/backbone/stem/conv/act/Relu_output_0, %onnx::Conv_1105, %onnx::Conv_1106), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.base.conv_module.ConvModule::stage1.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.0/conv/act/Relu_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.0/conv/act/Relu\"](%/backbone/stage1/stage1.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.base.conv_module.ConvModule::stage1.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/short_conv/conv/Conv\"](%/backbone/stage1/stage1.0/conv/act/Relu_output_0, %onnx::Conv_1108, %onnx::Conv_1109), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/short_conv/act/Relu\"](%/backbone/stage1/stage1.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/main_conv/conv/Conv\"](%/backbone/stage1/stage1.0/conv/act/Relu_output_0, %onnx::Conv_1111, %onnx::Conv_1112), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/main_conv/act/Relu\"](%/backbone/stage1/stage1.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/main_conv/act/Relu_output_0, %onnx::Conv_1114, %onnx::Conv_1115), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1117, %onnx::Conv_1118), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage1/stage1.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1120, %onnx::Conv_1121), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1123, %onnx::Conv_1124), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1126, %onnx::Conv_1127), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1129, %onnx::Conv_1130), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage1/stage1.1/Concat_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage1/stage1.1/Concat\"](%/backbone/stage1/stage1.1/blocks/blocks.2/Add_output_0, %/backbone/stage1/stage1.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/conv/Conv_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/final_conv/conv/Conv\"](%/backbone/stage1/stage1.1/Concat_output_0, %onnx::Conv_1132, %onnx::Conv_1133), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/act/Relu_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/final_conv/act/Relu\"](%/backbone/stage1/stage1.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.0/conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage2/stage2.0/conv/conv/Conv\"](%/backbone/stage1/stage1.1/final_conv/act/Relu_output_0, %onnx::Conv_1135, %onnx::Conv_1136), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.base.conv_module.ConvModule::stage2.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.0/conv/act/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.0/conv/act/Relu\"](%/backbone/stage2/stage2.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.base.conv_module.ConvModule::stage2.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/short_conv/conv/Conv\"](%/backbone/stage2/stage2.0/conv/act/Relu_output_0, %onnx::Conv_1138, %onnx::Conv_1139), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/short_conv/act/Relu\"](%/backbone/stage2/stage2.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/main_conv/conv/Conv\"](%/backbone/stage2/stage2.0/conv/act/Relu_output_0, %onnx::Conv_1141, %onnx::Conv_1142), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/main_conv/act/Relu\"](%/backbone/stage2/stage2.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/main_conv/act/Relu_output_0, %onnx::Conv_1144, %onnx::Conv_1145), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1147, %onnx::Conv_1148), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1150, %onnx::Conv_1151), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1153, %onnx::Conv_1154), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1156, %onnx::Conv_1157), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1159, %onnx::Conv_1160), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0, %onnx::Conv_1162, %onnx::Conv_1163), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv1/act/Relu_output_0, %onnx::Conv_1165, %onnx::Conv_1166), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0, %onnx::Conv_1168, %onnx::Conv_1169), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv1/act/Relu_output_0, %onnx::Conv_1171, %onnx::Conv_1172), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0, %onnx::Conv_1174, %onnx::Conv_1175), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv1/act/Relu_output_0, %onnx::Conv_1177, %onnx::Conv_1178), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/Concat_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage2/stage2.1/Concat\"](%/backbone/stage2/stage2.1/blocks/blocks.5/Add_output_0, %/backbone/stage2/stage2.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/final_conv/conv/Conv\"](%/backbone/stage2/stage2.1/Concat_output_0, %onnx::Conv_1180, %onnx::Conv_1181), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/act/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/final_conv/act/Relu\"](%/backbone/stage2/stage2.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.0/conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage3/stage3.0/conv/conv/Conv\"](%/backbone/stage2/stage2.1/final_conv/act/Relu_output_0, %onnx::Conv_1183, %onnx::Conv_1184), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.base.conv_module.ConvModule::stage3.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.0/conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.0/conv/act/Relu\"](%/backbone/stage3/stage3.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.base.conv_module.ConvModule::stage3.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/short_conv/conv/Conv\"](%/backbone/stage3/stage3.0/conv/act/Relu_output_0, %onnx::Conv_1186, %onnx::Conv_1187), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/short_conv/act/Relu\"](%/backbone/stage3/stage3.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/main_conv/conv/Conv\"](%/backbone/stage3/stage3.0/conv/act/Relu_output_0, %onnx::Conv_1189, %onnx::Conv_1190), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/main_conv/act/Relu\"](%/backbone/stage3/stage3.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/main_conv/act/Relu_output_0, %onnx::Conv_1192, %onnx::Conv_1193), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1195, %onnx::Conv_1196), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1198, %onnx::Conv_1199), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1201, %onnx::Conv_1202), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1204, %onnx::Conv_1205), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1207, %onnx::Conv_1208), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0, %onnx::Conv_1210, %onnx::Conv_1211), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv1/act/Relu_output_0, %onnx::Conv_1213, %onnx::Conv_1214), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0, %onnx::Conv_1216, %onnx::Conv_1217), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv1/act/Relu_output_0, %onnx::Conv_1219, %onnx::Conv_1220), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0, %onnx::Conv_1222, %onnx::Conv_1223), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv1/act/Relu_output_0, %onnx::Conv_1225, %onnx::Conv_1226), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0, %onnx::Conv_1228, %onnx::Conv_1229), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv1/act/Relu_output_0, %onnx::Conv_1231, %onnx::Conv_1232), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0, %onnx::Conv_1234, %onnx::Conv_1235), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv1/act/Relu_output_0, %onnx::Conv_1237, %onnx::Conv_1238), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0, %onnx::Conv_1240, %onnx::Conv_1241), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv1/act/Relu_output_0, %onnx::Conv_1243, %onnx::Conv_1244), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage3/stage3.1/Concat\"](%/backbone/stage3/stage3.1/blocks/blocks.8/Add_output_0, %/backbone/stage3/stage3.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/final_conv/conv/Conv\"](%/backbone/stage3/stage3.1/Concat_output_0, %onnx::Conv_1246, %onnx::Conv_1247), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/final_conv/act/Relu\"](%/backbone/stage3/stage3.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.0/conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage4/stage4.0/conv/conv/Conv\"](%/backbone/stage3/stage3.1/final_conv/act/Relu_output_0, %onnx::Conv_1249, %onnx::Conv_1250), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.base.conv_module.ConvModule::stage4.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.0/conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.0/conv/act/Relu\"](%/backbone/stage4/stage4.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.base.conv_module.ConvModule::stage4.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/short_conv/conv/Conv\"](%/backbone/stage4/stage4.0/conv/act/Relu_output_0, %onnx::Conv_1252, %onnx::Conv_1253), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/short_conv/act/Relu\"](%/backbone/stage4/stage4.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/main_conv/conv/Conv\"](%/backbone/stage4/stage4.0/conv/act/Relu_output_0, %onnx::Conv_1255, %onnx::Conv_1256), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/main_conv/act/Relu\"](%/backbone/stage4/stage4.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/main_conv/act/Relu_output_0, %onnx::Conv_1258, %onnx::Conv_1259), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1261, %onnx::Conv_1262), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage4/stage4.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1264, %onnx::Conv_1265), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1267, %onnx::Conv_1268), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1270, %onnx::Conv_1271), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1273, %onnx::Conv_1274), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage4/stage4.1/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.1/Concat\"](%/backbone/stage4/stage4.1/blocks/blocks.2/Add_output_0, %/backbone/stage4/stage4.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/final_conv/conv/Conv\"](%/backbone/stage4/stage4.1/Concat_output_0, %onnx::Conv_1276, %onnx::Conv_1277), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/final_conv/act/Relu\"](%/backbone/stage4/stage4.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/conv/Conv\"](%/backbone/stage4/stage4.1/final_conv/act/Relu_output_0, %onnx::Conv_1279, %onnx::Conv_1280), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/act/Relu\"](%/backbone/stage4/stage4.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.2/poolings/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings/MaxPool\"](%/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_1/MaxPool\"](%/backbone/stage4/stage4.2/poolings/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_2/MaxPool\"](%/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/Concat_output_0 : Float(1, 320, 6, 6, strides=[11520, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.2/Concat\"](%/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0, %/backbone/stage4/stage4.2/poolings/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2 # /content/ModelAssistant/sscma/models/layers/sppf.py:57:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/conv/Conv\"](%/backbone/stage4/stage4.2/Concat_output_0, %onnx::Conv_1282, %onnx::Conv_1283), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/act/Relu\"](%/backbone/stage4/stage4.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/reduce_layers.2/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/reduce_layers.2/conv/conv/Conv\"](%/backbone/stage4/stage4.2/conv2/conv/act/Relu_output_0, %onnx::Conv_1285, %onnx::Conv_1286), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::reduce_layers.2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/reduce_layers.2/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/reduce_layers.2/conv/act/Relu\"](%/neck/reduce_layers.2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::reduce_layers.2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/upsample_layers.0/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.0/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.0/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Resize_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.0/Resize\"](%/neck/reduce_layers.2/conv/act/Relu_output_0, %/neck/upsample_layers.0/Constant_1_output_0, %/neck/upsample_layers.0/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_output_0 : Float(1, 160, 12, 12, strides=[23040, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat\"](%/neck/upsample_layers.0/Resize_output_0, %/backbone/stage3/stage3.1/final_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:352:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_1288, %onnx::Conv_1289), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_1291, %onnx::Conv_1292), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/act/Relu_output_0, %onnx::Conv_1294, %onnx::Conv_1295), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1297, %onnx::Conv_1298), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/Concat\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0, %onnx::Conv_1300, %onnx::Conv_1301), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/act/Relu_output_0, %onnx::Conv_1303, %onnx::Conv_1304), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.base.conv_module.ConvModule::top_down_layers.0.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.base.conv_module.ConvModule::top_down_layers.0.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/upsample_layers.1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.1/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.1/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Resize_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.1/Resize\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0, %/neck/upsample_layers.1/Constant_1_output_0, %/neck/upsample_layers.1/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_1_output_0 : Float(1, 80, 24, 24, strides=[46080, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_1\"](%/neck/upsample_layers.1/Resize_output_0, %/backbone/stage2/stage2.1/final_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:352:0\n",
            "  %/neck/top_down_layers.1/short_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/short_conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_1306, %onnx::Conv_1307), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/short_conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/short_conv/act/Relu\"](%/neck/top_down_layers.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/main_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/main_conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_1309, %onnx::Conv_1310), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/main_conv/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/main_conv/act/Relu\"](%/neck/top_down_layers.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv\"](%/neck/top_down_layers.1/main_conv/act/Relu_output_0, %onnx::Conv_1312, %onnx::Conv_1313), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/act/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1315, %onnx::Conv_1316), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/act/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/Concat_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.1/Concat\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/top_down_layers.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/top_down_layers.1/final_conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/final_conv/conv/Conv\"](%/neck/top_down_layers.1/Concat_output_0, %onnx::Conv_1318, %onnx::Conv_1319), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/final_conv/act/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/final_conv/act/Relu\"](%/neck/top_down_layers.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/downsample_layers.0/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.0/conv/conv/Conv\"](%/neck/top_down_layers.1/final_conv/act/Relu_output_0, %onnx::Conv_1321, %onnx::Conv_1322), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.0/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.0/conv/act/Relu\"](%/neck/downsample_layers.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/Concat_2_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_2\"](%/neck/downsample_layers.0/conv/act/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:364:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/short_conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_1324, %onnx::Conv_1325), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/short_conv/act/Relu\"](%/neck/bottom_up_layers.0/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/main_conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_1327, %onnx::Conv_1328), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/main_conv/act/Relu\"](%/neck/bottom_up_layers.0/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv\"](%/neck/bottom_up_layers.0/main_conv/act/Relu_output_0, %onnx::Conv_1330, %onnx::Conv_1331), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/act/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1333, %onnx::Conv_1334), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/act/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.0/Concat\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/bottom_up_layers.0/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/final_conv/conv/Conv\"](%/neck/bottom_up_layers.0/Concat_output_0, %onnx::Conv_1336, %onnx::Conv_1337), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/act/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/final_conv/act/Relu\"](%/neck/bottom_up_layers.0/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/downsample_layers.1/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.1/conv/conv/Conv\"](%/neck/bottom_up_layers.0/final_conv/act/Relu_output_0, %onnx::Conv_1339, %onnx::Conv_1340), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.1/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.1/conv/act/Relu\"](%/neck/downsample_layers.1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/Concat_3_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_3\"](%/neck/downsample_layers.1/conv/act/Relu_output_0, %/neck/reduce_layers.2/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:364:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/short_conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_1342, %onnx::Conv_1343), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/short_conv/act/Relu\"](%/neck/bottom_up_layers.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/main_conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_1345, %onnx::Conv_1346), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/main_conv/act/Relu\"](%/neck/bottom_up_layers.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv\"](%/neck/bottom_up_layers.1/main_conv/act/Relu_output_0, %onnx::Conv_1348, %onnx::Conv_1349), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/act/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1351, %onnx::Conv_1352), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/act/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.1/Concat\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/bottom_up_layers.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/final_conv/conv/Conv\"](%/neck/bottom_up_layers.1/Concat_output_0, %onnx::Conv_1354, %onnx::Conv_1355), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/act/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/final_conv/act/Relu\"](%/neck/bottom_up_layers.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/convs_pred.0/Conv_output_0 : Float(1, 18, 24, 24, strides=[10368, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.0/Conv\"](%/neck/top_down_layers.1/final_conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.0.weight, %bbox_head.head_module.convs_pred.0.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_output_0 : Float(1, 18, 24, 24, strides=[10368, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid\"](%/convs_pred.0/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    6  576 [ CPULongType{4} ], onnx_name=\"/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_output_0 : Float(1, 3, 6, 576, strides=[10368, 3456, 576, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape\"](%/Sigmoid_output_0, %/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_output_0 : Float(1, 3, 576, 6, strides=[10368, 3456, 6, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose\"](%/Reshape_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/convs_pred.1/Conv_output_0 : Float(1, 18, 12, 12, strides=[2592, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.1/Conv\"](%/neck/bottom_up_layers.0/final_conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.1.weight, %bbox_head.head_module.convs_pred.1.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_1_output_0 : Float(1, 18, 12, 12, strides=[2592, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_1\"](%/convs_pred.1/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    6  144 [ CPULongType{4} ], onnx_name=\"/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_1_output_0 : Float(1, 3, 6, 144, strides=[2592, 864, 144, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_1\"](%/Sigmoid_1_output_0, %/Constant_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_1_output_0 : Float(1, 3, 144, 6, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_1\"](%/Reshape_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/convs_pred.2/Conv_output_0 : Float(1, 18, 6, 6, strides=[648, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.2/Conv\"](%/neck/bottom_up_layers.1/final_conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.2.weight, %bbox_head.head_module.convs_pred.2.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_2_output_0 : Float(1, 18, 6, 6, strides=[648, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_2\"](%/convs_pred.2/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3   6  36 [ CPULongType{4} ], onnx_name=\"/Constant_2\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_2_output_0 : Float(1, 3, 6, 36, strides=[648, 216, 36, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_2\"](%/Sigmoid_2_output_0, %/Constant_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_2_output_0 : Float(1, 3, 36, 6, strides=[648, 216, 6, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_2\"](%/Reshape_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/Constant_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 24  24 [ CPULongType{2} ], onnx_name=\"/Constant_3\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_4_output_0 : Long(24, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_4\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_output_0 : Long(24, 24, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand\"](%/Constant_4_output_0, %/Constant_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_5_output_0 : Long(1, 24, strides=[24, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_5\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_1_output_0 : Long(24, 24, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_1\"](%/Constant_5_output_0, %/Constant_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_output_0 : Long(24, 24, 1, strides=[24, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze\"](%/Expand_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_1_output_0 : Long(24, 24, 1, strides=[24, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_1\"](%/Expand_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_output_0 : Long(24, 24, 2, strides=[48, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat\"](%/Unsqueeze_output_0, %/Unsqueeze_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_6_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  24  24   2 [ CPULongType{5} ], onnx_name=\"/Constant_6\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_7\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape\"](%/Constant_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_8\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/ConstantOfShape_output_0, %/Constant_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal\"](%/Constant_6_output_0, %/Mul_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where\"](%/Equal_output_0, %/ConstantOfShape_output_0, %/Constant_6_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_2_output_0 : Long(1, 1, 24, 24, 2, strides=[1152, 1152, 48, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_2\"](%/Concat_output_0, %/Where_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_9\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_3_output_0 : Long(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_3\"](%/Expand_2_output_0, %/Constant_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_output_0 : Float(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast\"](%/Reshape_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_1_output_0 : Float(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_1\"](%/Cast_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_902 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    10  13  (1,2,.,.) =    16  30  (1,3,.,.) =    33  23 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_10_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  576    2 [ CPULongType{4} ], onnx_name=\"/Constant_10\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_11\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_1\"](%/Constant_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_12\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/ConstantOfShape_1_output_0, %/Constant_12_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_1\"](%/Constant_10_output_0, %/Mul_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_1\"](%/Equal_1_output_0, %/ConstantOfShape_1_output_0, %/Constant_10_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_3_output_0 : Long(1, 3, 576, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_3\"](%onnx::Expand_902, %/Where_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_2_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_2\"](%/Expand_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_3_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_3\"](%/Cast_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_output_0 : Float(1, 3, 576, 2, strides=[10368, 3456, 6, 1], requires_grad=0, device=cpu), %/Split_output_1 : Float(1, 3, 576, 2, strides=[10368, 3456, 6, 1], requires_grad=0, device=cpu), %/Split_output_2 : Float(1, 3, 576, 2, strides=[10368, 3456, 6, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 2], onnx_name=\"/Split\"](%/Transpose_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_13\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_2_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_2\"](%/Split_output_0, %/Constant_13_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_14\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub\"](%/Mul_2_output_0, %/Constant_14_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Sub_output_0, %/Cast_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/Constant_15\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_3_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_3\"](%/Add_output_0, %/Constant_15_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_16\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_4_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_4\"](%/Split_output_1, %/Constant_16_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_5_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_5\"](%/Mul_4_output_0, %/Mul_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_6_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_6\"](%/Mul_5_output_0, %/Cast_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_17\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_7_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_7\"](%/Split_output_2, %/Constant_17_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_1_output_0 : Float(1, 3, 576, 6, strides=[10368, 3456, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_1\"](%/Mul_3_output_0, %/Mul_6_output_0, %/Mul_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_18_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  6 [ CPULongType{3} ], onnx_name=\"/Constant_18\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_4_output_0 : Float(1, 1728, 6, strides=[10368, 6, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_4\"](%/Concat_1_output_0, %/Constant_18_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Constant_19_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 12  12 [ CPULongType{2} ], onnx_name=\"/Constant_19\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_20_output_0 : Long(12, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_20\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_4_output_0 : Long(12, 12, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_4\"](%/Constant_20_output_0, %/Constant_19_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_21_output_0 : Long(1, 12, strides=[12, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_21\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_5_output_0 : Long(12, 12, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_5\"](%/Constant_21_output_0, %/Constant_19_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_2_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_2\"](%/Expand_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_3_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_3\"](%/Expand_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_2_output_0 : Long(12, 12, 2, strides=[24, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_2\"](%/Unsqueeze_2_output_0, %/Unsqueeze_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_22_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  12  12   2 [ CPULongType{5} ], onnx_name=\"/Constant_22\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_23\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_2\"](%/Constant_23_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_24\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_8_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_8\"](%/ConstantOfShape_2_output_0, %/Constant_24_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_2_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_2\"](%/Constant_22_output_0, %/Mul_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_2\"](%/Equal_2_output_0, %/ConstantOfShape_2_output_0, %/Constant_22_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_6_output_0 : Long(1, 1, 12, 12, 2, strides=[288, 288, 24, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_6\"](%/Concat_2_output_0, %/Where_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_25_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_25\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_5_output_0 : Long(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_5\"](%/Expand_6_output_0, %/Constant_25_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_4_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_4\"](%/Reshape_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_5_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_5\"](%/Cast_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_982 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    30  61  (1,2,.,.) =    62  45  (1,3,.,.) =     59  119 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_26_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  144    2 [ CPULongType{4} ], onnx_name=\"/Constant_26\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_27\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_3\"](%/Constant_27_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_28_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_28\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_9\"](%/ConstantOfShape_3_output_0, %/Constant_28_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_3\"](%/Constant_26_output_0, %/Mul_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_3\"](%/Equal_3_output_0, %/ConstantOfShape_3_output_0, %/Constant_26_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_7_output_0 : Long(1, 3, 144, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_7\"](%onnx::Expand_982, %/Where_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_6_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_6\"](%/Expand_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_7_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_7\"](%/Cast_6_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_1_output_0 : Float(1, 3, 144, 2, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu), %/Split_1_output_1 : Float(1, 3, 144, 2, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu), %/Split_1_output_2 : Float(1, 3, 144, 2, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 2], onnx_name=\"/Split_1\"](%/Transpose_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_29_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_29\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_10_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_10\"](%/Split_1_output_0, %/Constant_29_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_30_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_30\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_1_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_1\"](%/Mul_10_output_0, %/Constant_30_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_1_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/Sub_1_output_0, %/Cast_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_31_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/Constant_31\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_11_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_11\"](%/Add_1_output_0, %/Constant_31_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_32_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_32\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_12_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_12\"](%/Split_1_output_1, %/Constant_32_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_13_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_13\"](%/Mul_12_output_0, %/Mul_12_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_14_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_14\"](%/Mul_13_output_0, %/Cast_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_33_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_33\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_15_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_15\"](%/Split_1_output_2, %/Constant_33_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_3_output_0 : Float(1, 3, 144, 6, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_3\"](%/Mul_11_output_0, %/Mul_14_output_0, %/Mul_15_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_34_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  6 [ CPULongType{3} ], onnx_name=\"/Constant_34\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_6_output_0 : Float(1, 432, 6, strides=[2592, 6, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_6\"](%/Concat_3_output_0, %/Constant_34_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Constant_35_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 6  6 [ CPULongType{2} ], onnx_name=\"/Constant_35\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_36_output_0 : Long(6, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{6,1} ], onnx_name=\"/Constant_36\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_8_output_0 : Long(6, 6, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_8\"](%/Constant_36_output_0, %/Constant_35_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_37_output_0 : Long(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{1,6} ], onnx_name=\"/Constant_37\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_9_output_0 : Long(6, 6, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_9\"](%/Constant_37_output_0, %/Constant_35_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_4_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_4\"](%/Expand_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_5_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_5\"](%/Expand_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_4_output_0 : Long(6, 6, 2, strides=[12, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_4\"](%/Unsqueeze_4_output_0, %/Unsqueeze_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_38_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  6  6  2 [ CPULongType{5} ], onnx_name=\"/Constant_38\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_39\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_4\"](%/Constant_39_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_40_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_40\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_16_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_16\"](%/ConstantOfShape_4_output_0, %/Constant_40_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_4_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_4\"](%/Constant_38_output_0, %/Mul_16_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_4\"](%/Equal_4_output_0, %/ConstantOfShape_4_output_0, %/Constant_38_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_10_output_0 : Long(1, 1, 6, 6, 2, strides=[72, 72, 12, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_10\"](%/Concat_4_output_0, %/Where_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_41_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_41\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_7_output_0 : Long(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_7\"](%/Expand_10_output_0, %/Constant_41_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_8_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_8\"](%/Reshape_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_9_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_9\"](%/Cast_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_1061 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    116   90  (1,2,.,.) =    156  198  (1,3,.,.) =    373  326 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_42_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3  36   2 [ CPULongType{4} ], onnx_name=\"/Constant_42\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_43\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_5\"](%/Constant_43_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_44_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_44\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_17\"](%/ConstantOfShape_5_output_0, %/Constant_44_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_5\"](%/Constant_42_output_0, %/Mul_17_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_5\"](%/Equal_5_output_0, %/ConstantOfShape_5_output_0, %/Constant_42_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_11_output_0 : Long(1, 3, 36, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_11\"](%onnx::Expand_1061, %/Where_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_10_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_10\"](%/Expand_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_11_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_11\"](%/Cast_10_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_2_output_0 : Float(1, 3, 36, 2, strides=[648, 216, 6, 1], requires_grad=0, device=cpu), %/Split_2_output_1 : Float(1, 3, 36, 2, strides=[648, 216, 6, 1], requires_grad=0, device=cpu), %/Split_2_output_2 : Float(1, 3, 36, 2, strides=[648, 216, 6, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 2], onnx_name=\"/Split_2\"](%/Transpose_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_45_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_45\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_18_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_18\"](%/Split_2_output_0, %/Constant_45_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_46_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_46\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_2_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_2\"](%/Mul_18_output_0, %/Constant_46_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_2_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_2\"](%/Sub_2_output_0, %/Cast_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_47_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name=\"/Constant_47\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_19_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_19\"](%/Add_2_output_0, %/Constant_47_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_48_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_48\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_20_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_20\"](%/Split_2_output_1, %/Constant_48_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_21_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_21\"](%/Mul_20_output_0, %/Mul_20_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_22_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_22\"](%/Mul_21_output_0, %/Cast_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_49_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_49\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_23_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_23\"](%/Split_2_output_2, %/Constant_49_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_5_output_0 : Float(1, 3, 36, 6, strides=[648, 216, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_5\"](%/Mul_19_output_0, %/Mul_22_output_0, %/Mul_23_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_50_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  6 [ CPULongType{3} ], onnx_name=\"/Constant_50\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_8_output_0 : Float(1, 108, 6, strides=[648, 6, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_8\"](%/Concat_5_output_0, %/Constant_50_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %output : Float(1, 2268, 6, strides=[13608, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_6\"](%/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:135:0\n",
            "  return (%output)\n",
            "\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "ONNX: Successfully export model: /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float32.onnx\n",
            "pnnxparam = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.pnnx.param\n",
            "pnnxbin = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.pnnx.bin\n",
            "pnnxpy = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.pnnx.py\n",
            "pnnxonnx = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.pnnx.onnx\n",
            "ncnnparam = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.ncnn.param\n",
            "ncnnbin = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.ncnn.bin\n",
            "ncnnpy = /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_float.ncnn.py\n",
            "fp16 = 1\n",
            "optlevel = 2\n",
            "device = cpu\n",
            "inputshape = [1,3,192,192]f32\n",
            "inputshape2 = \n",
            "customop = \n",
            "moduleop = \n",
            "############# pass_level0\n",
            "inline module = sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet\n",
            "inline module = sscma.models.base.conv_module.ConvModule\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.csp_layer.CSPLayer\n",
            "inline module = sscma.models.layers.csp_layer.DarknetBottleneck\n",
            "inline module = sscma.models.layers.sppf.SPPFBottleneck\n",
            "inline module = sscma.models.necks.fpn.YOLOv5PAFPN\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "inline module = sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet\n",
            "inline module = sscma.models.base.conv_module.ConvModule\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.csp_layer.CSPLayer\n",
            "inline module = sscma.models.layers.csp_layer.DarknetBottleneck\n",
            "inline module = sscma.models.layers.sppf.SPPFBottleneck\n",
            "inline module = sscma.models.necks.fpn.YOLOv5PAFPN\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "\n",
            "----------------\n",
            "\n",
            "############# pass_level1\n",
            "############# pass_level2\n",
            "############# pass_level3\n",
            "############# pass_level4\n",
            "############# pass_level5\n",
            "############# pass_ncnn\n"
          ]
        }
      ],
      "source": [
        "!sscma.export configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=person_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=person_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjiegHLbMhT-"
      },
      "source": [
        "### 📝Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xre344cMhT-"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsCH0A-fMhT-"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=person_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=person_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI7OBdfMMhT-"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hpBMjyQMhT-"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=person_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=person_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SndeifpbMhT_"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faAkgH18MhT_"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=person_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=person_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRTFIhw4MhT_"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dqnWPrr4MhT_",
        "outputId": "05c5af2a-6e61-4e8d-8272-b3dcf60af3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_int8.pkl\n",
            "11/24 08:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1106926601\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.5\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1106926601\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "11/24 08:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'person_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'person_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.09000000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'person_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/person_Detection_Swift-YOLO_192/epoch_10_int8.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='person_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'person_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'person_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/person_Detection_Swift-YOLO_192/20241124_085308'}\n",
            "2024-11-24 08:53:11.410645: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-24 08:53:11.443165: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-24 08:53:11.453304: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-24 08:53:11.474118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-24 08:53:13.157291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "11/24 08:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "11/24 08:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/930 [00:00<?, ?it/s]11/24 08:53:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "11/24 08:53:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 930/930 [00:12<00:00, 74.26it/s]\n",
            "11/24 08:53:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.420\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
            "11/24 08:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.431 0.775 0.420 0.020 0.355 0.562\n",
            "{'coco/bbox_mAP': 0.431, 'coco/bbox_mAP_50': 0.775, 'coco/bbox_mAP_75': 0.42, 'coco/bbox_mAP_s': 0.02, 'coco/bbox_mAP_m': 0.355, 'coco/bbox_mAP_l': 0.562}\n",
            "FPS: 103.379490 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=person_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=person_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=person_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPc3o0HQMhT_"
      },
      "source": [
        "## 🤖 Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u1_VANHRMhT_",
        "outputId": "428fa8c9-5164-4e0b-c71b-381bf97956a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 130M\n",
            "drwxr-xr-x 3 root root 4.0K Nov 24 08:26 \u001b[0m\u001b[01;34m20241124_082607\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Nov 24 08:49 \u001b[01;34m20241124_084858\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Nov 24 08:53 \u001b[01;34m20241124_085308\u001b[0m/\n",
            "-rw-r--r-- 1 root root 8.2M Nov 24 08:38 best_coco_bbox_mAP_epoch_10.pth\n",
            "drwxr-xr-x 4 root root 4.0K Nov 24 08:19 \u001b[01;34mdataset\u001b[0m/\n",
            "-rw-r--r-- 1 root root  51M Jan  3  2024 dataset.zip\n",
            "-rw-r--r-- 1 root root 4.4M Nov 24 08:49 epoch_10_float32.onnx\n",
            "-rw-r--r-- 1 root root 1.5K Nov 24 08:49 epoch_10_float32_summary_Ethos_U55_High_End_Embedded.csv\n",
            "-rw-r--r-- 1 root root 3.7M Nov 24 08:49 epoch_10_float32.tflite\n",
            "-rw-r--r-- 1 root root 3.7M Nov 24 08:49 epoch_10_float32_vela.tflite\n",
            "-rw-r--r-- 1 root root 1.9M Nov 24 08:49 epoch_10_float.ncnn.bin\n",
            "-rw-r--r-- 1 root root  19K Nov 24 08:49 epoch_10_float.ncnn.param\n",
            "-rw-r--r-- 1 root root  714 Nov 24 08:49 epoch_10_float.ncnn.py\n",
            "-rw-r--r-- 1 root root 3.7M Nov 24 08:49 epoch_10_float.pnnx.bin\n",
            "-rw-r--r-- 1 root root 1.9M Nov 24 08:49 epoch_10_float.pnnx.onnx\n",
            "-rw-r--r-- 1 root root  45K Nov 24 08:49 epoch_10_float.pnnx.param\n",
            "-rw-r--r-- 1 root root  56K Nov 24 08:49 epoch_10_float.pnnx.py\n",
            "-rw-r--r-- 1 root root  194 Nov 24 08:53 epoch_10_int8.pkl\n",
            "-rw-r--r-- 1 root root 1.7K Nov 24 08:49 epoch_10_int8_summary_Ethos_U55_High_End_Embedded.csv\n",
            "-rw-r--r-- 1 root root 1.1M Nov 24 08:49 epoch_10_int8.tflite\n",
            "-rw-r--r-- 1 root root 1.2M Nov 24 08:49 epoch_10_int8_vela.tflite\n",
            "-rw-r--r-- 1 root root  12M Nov 24 08:38 epoch_10.pth\n",
            "-rw-r--r-- 1 root root  12M Nov 24 08:32 epoch_5.pth\n",
            "-rw-r--r-- 1 root root   68 Nov 24 08:38 last_checkpoint\n",
            "-rw-r--r-- 1 root root  23M Jan  4  2024 pretrain.pth\n",
            "drwxr-xr-x 2 root root 4.0K Nov 24 08:49 \u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw-r--r-- 1 root root  16K Nov 24 08:53 swift_yolo_tiny_1xb16_300e_coco.py\n",
            "-rw-r--r-- 1 root root  11K Nov 24 08:49 yolodetector_q_config.yml\n",
            "-rw-r--r-- 1 root root 3.8M Nov 24 08:49 yolodetector_q.pth\n",
            "-rw-r--r-- 1 root root  97K Nov 24 08:49 yolodetector_q.py\n"
          ]
        }
      ],
      "source": [
        "%ls -lh person_Detection_Swift-YOLO_192/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CDoFRW9MhUA"
      },
      "source": [
        "### Thanks for Trying Out SSCMA 🎉\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star ✨ on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}